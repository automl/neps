{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction and Installation Installation Using pip pip install neural-pipeline-search Optional: Specific torch versions If you run into any issues regarding versions of the torch ecosystem (like needing cuda enabled versions), you might want to use our utility python -m neps.utils.install_torch This script asks for the torch version you want and installs all the torch libraries needed for the neps package with that version. For the installation pip of the active python environment is used.","title":"Introduction and Installation"},{"location":"#introduction-and-installation","text":"","title":"Introduction and Installation"},{"location":"#installation","text":"Using pip pip install neural-pipeline-search","title":"Installation"},{"location":"#optional-specific-torch-versions","text":"If you run into any issues regarding versions of the torch ecosystem (like needing cuda enabled versions), you might want to use our utility python -m neps.utils.install_torch This script asks for the torch version you want and installs all the torch libraries needed for the neps package with that version. For the installation pip of the active python environment is used.","title":"Optional: Specific torch versions"},{"location":"analyse/","text":"Analysing Runs Status To show status information about a neural pipeline search use python -m neps.status WORKING_DIRECTORY If you need more status information than is printed per default (e.g., the best config over time), please have a look at python -m neps.status --help To show the status repeatedly, on unix systems you can use watch --interval 30 python -m neps.status WORKING_DIRECTORY","title":"Analysing Runs"},{"location":"analyse/#analysing-runs","text":"","title":"Analysing Runs"},{"location":"analyse/#status","text":"To show status information about a neural pipeline search use python -m neps.status WORKING_DIRECTORY If you need more status information than is printed per default (e.g., the best config over time), please have a look at python -m neps.status --help To show the status repeatedly, on unix systems you can use watch --interval 30 python -m neps.status WORKING_DIRECTORY","title":"Status"},{"location":"getting_started/","text":"","title":"Getting Started"},{"location":"neps_run/","text":"","title":"The neps.run Function"},{"location":"parallelization/","text":"Parallelization In order to run a neural pipeline search with multiple processes or multiple machines, simply call neps.run multiple times. All calls to neps.run need to use the same working_directory on the same filesystem, otherwise there is no synchronization between the neps.run 's.","title":"Parallelization"},{"location":"parallelization/#parallelization","text":"In order to run a neural pipeline search with multiple processes or multiple machines, simply call neps.run multiple times. All calls to neps.run need to use the same working_directory on the same filesystem, otherwise there is no synchronization between the neps.run 's.","title":"Parallelization"},{"location":"pipeline_space/","text":"","title":"The pipeline_space"},{"location":"run_pipeline/","text":"","title":"The run_pipeline Function"},{"location":"contributing/","text":"Introduction Getting Help Ask in the neps developer chat on mattermost or any contributor directly. If you are not in the mattermost chat yet, ask to get access. Development Workflow We loosely practice trunk-based-development : We work almost exclusively on the master branch We commit, push, and pull often We automatically run code quality checks before every commit (using pre-commit ) We manually run tests (using pytest ) before every critical push and automatically afterwards (using github actions ) Examples and Tests We document major features with an example (see neps_examples ). When adding a new example also include it in the example README . These examples also serve as integration tests, which we run from the main directory via pytest before every critical push. Running the tests will create a temporary directory tests_tmpdir that includes the output of the last three test executions. To speedup testing for developers, we only run a core set of tests per default. To run all tests use pytest -m all_examples On github, we always run all examples. If tests fail for you on the master: Try running the tests with a fresh environment install. If issues persist, notify others in the neps developers chat on mattermost.","title":"Introduction"},{"location":"contributing/#introduction","text":"","title":"Introduction"},{"location":"contributing/#getting-help","text":"Ask in the neps developer chat on mattermost or any contributor directly. If you are not in the mattermost chat yet, ask to get access.","title":"Getting Help"},{"location":"contributing/#development-workflow","text":"We loosely practice trunk-based-development : We work almost exclusively on the master branch We commit, push, and pull often We automatically run code quality checks before every commit (using pre-commit ) We manually run tests (using pytest ) before every critical push and automatically afterwards (using github actions )","title":"Development Workflow"},{"location":"contributing/#examples-and-tests","text":"We document major features with an example (see neps_examples ). When adding a new example also include it in the example README . These examples also serve as integration tests, which we run from the main directory via pytest before every critical push. Running the tests will create a temporary directory tests_tmpdir that includes the output of the last three test executions. To speedup testing for developers, we only run a core set of tests per default. To run all tests use pytest -m all_examples On github, we always run all examples. If tests fail for you on the master: Try running the tests with a fresh environment install. If issues persist, notify others in the neps developers chat on mattermost.","title":"Examples and Tests"},{"location":"contributing/dependencies/","text":"Managing Dependencies To manage dependencies and for package distribution we use poetry (replaces pip). Add dependencies To install a dependency use poetry add dependency and commit the updated pyproject.toml to git. For more advanced dependency management see examples in pyproject.toml or have a look at the poetry documentation . Install dependencies added by others When other contributors added dependencies to pyproject.toml , you can install them via poetry lock poetry install","title":"Managing Dependencies"},{"location":"contributing/dependencies/#managing-dependencies","text":"To manage dependencies and for package distribution we use poetry (replaces pip).","title":"Managing Dependencies"},{"location":"contributing/dependencies/#add-dependencies","text":"To install a dependency use poetry add dependency and commit the updated pyproject.toml to git. For more advanced dependency management see examples in pyproject.toml or have a look at the poetry documentation .","title":"Add dependencies"},{"location":"contributing/dependencies/#install-dependencies-added-by-others","text":"When other contributors added dependencies to pyproject.toml , you can install them via poetry lock poetry install","title":"Install dependencies added by others"},{"location":"contributing/documentation/","text":"Documentation We use MkDocs , more specifically Material for MkDocs for documentation. Source files for the documentation are at docs and configuration at mkdocs.yml . To build and view the documentation run mkdocs build mkdocs serve and open the URL shown by the mkdocs serve command.","title":"Documentation"},{"location":"contributing/documentation/#documentation","text":"We use MkDocs , more specifically Material for MkDocs for documentation. Source files for the documentation are at docs and configuration at mkdocs.yml . To build and view the documentation run mkdocs build mkdocs serve and open the URL shown by the mkdocs serve command.","title":"Documentation"},{"location":"contributing/faq/","text":"Frequently Asked Questions Pre-commit: How to not run hooks? To commit without running pre-commit use git commit --no-verify -m <COMMIT MESSAGE> . Pylint: How to ignore warnings? There are two options: Disable the warning locally: code = \"foo\" # pylint: disable=ERROR_CODE Make sure to use the named version of the error (e.g., unspecified-encoding , not W1514 ). Remove warning in pyproject.toml that we do not consider useful (do not catch bugs, do not increase code quality). Mypy: How to ignore warnings? There are two options: Disable the warning locally: code = \"foo\" # type: ignore[ERROR_CODE] If you know what you are doing, you can add the whole module to the [[tool.mypy.overrides]] section. This is useful e.g., when adding new files that are in early stage development. Black: How to not format code parts? x = 2 # fmt: off or for blocks # fmt: off x = 2 y = x + 1 # fmt: on What is Editorconfig about? Editorconfig allows to set line lengths and other display parameters automatically based on a .editorconfig file. Many editors have native support (e.g., PyCharm) so you do not need to do anything. For other editors (e.g., VSCode), you need to install a plugin .","title":"FAQ"},{"location":"contributing/faq/#frequently-asked-questions","text":"","title":"Frequently Asked Questions"},{"location":"contributing/faq/#pre-commit-how-to-not-run-hooks","text":"To commit without running pre-commit use git commit --no-verify -m <COMMIT MESSAGE> .","title":"Pre-commit: How to not run hooks?"},{"location":"contributing/faq/#pylint-how-to-ignore-warnings","text":"There are two options: Disable the warning locally: code = \"foo\" # pylint: disable=ERROR_CODE Make sure to use the named version of the error (e.g., unspecified-encoding , not W1514 ). Remove warning in pyproject.toml that we do not consider useful (do not catch bugs, do not increase code quality).","title":"Pylint: How to ignore warnings?"},{"location":"contributing/faq/#mypy-how-to-ignore-warnings","text":"There are two options: Disable the warning locally: code = \"foo\" # type: ignore[ERROR_CODE] If you know what you are doing, you can add the whole module to the [[tool.mypy.overrides]] section. This is useful e.g., when adding new files that are in early stage development.","title":"Mypy: How to ignore warnings?"},{"location":"contributing/faq/#black-how-to-not-format-code-parts","text":"x = 2 # fmt: off or for blocks # fmt: off x = 2 y = x + 1 # fmt: on","title":"Black: How to not format code parts?"},{"location":"contributing/faq/#what-is-editorconfig-about","text":"Editorconfig allows to set line lengths and other display parameters automatically based on a .editorconfig file. Many editors have native support (e.g., PyCharm) so you do not need to do anything. For other editors (e.g., VSCode), you need to install a plugin .","title":"What is Editorconfig about?"},{"location":"contributing/installation/","text":"Installation for Contributors There are three required steps and one optional: Optional: Install miniconda and create an environment Install poetry Install the neps package using poetry Activate pre-commit for the repository For instructions see below. 1. Optional: Install miniconda and create an environment To manage python versions install e.g., miniconda with wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh -O install_miniconda.sh bash install_miniconda.sh -b -p $HOME /.conda # Change to place of preference rm install_miniconda.sh Consider running ~/.conda/bin/conda init or ~/.conda/bin/conda init zsh . Then finally create the environment and activate it conda create -n neps python = 3 .7.5 conda activate neps 2. Install poetry First, install poetry, e.g., via curl -sSL https://install.python-poetry.org | python3 - Then consider appending export PATH = \" $HOME /.local/bin: $PATH \" to your .zshrc / .bashrc or alternatively simply running the export manually. 3. Install the neps Package Using poetry Inside the main directory of neps run poetry install To install specific versions of torch (e.g., cuda enabled versions) you might want to use our utility python -m neps.utils.install_torch 4. Activate pre-commit for the repository With the python environment used to install the neps package run in the main directory of neps pre-commit install","title":"Installation for Contributors"},{"location":"contributing/installation/#installation-for-contributors","text":"There are three required steps and one optional: Optional: Install miniconda and create an environment Install poetry Install the neps package using poetry Activate pre-commit for the repository For instructions see below.","title":"Installation for Contributors"},{"location":"contributing/installation/#1-optional-install-miniconda-and-create-an-environment","text":"To manage python versions install e.g., miniconda with wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh -O install_miniconda.sh bash install_miniconda.sh -b -p $HOME /.conda # Change to place of preference rm install_miniconda.sh Consider running ~/.conda/bin/conda init or ~/.conda/bin/conda init zsh . Then finally create the environment and activate it conda create -n neps python = 3 .7.5 conda activate neps","title":"1. Optional: Install miniconda and create an environment"},{"location":"contributing/installation/#2-install-poetry","text":"First, install poetry, e.g., via curl -sSL https://install.python-poetry.org | python3 - Then consider appending export PATH = \" $HOME /.local/bin: $PATH \" to your .zshrc / .bashrc or alternatively simply running the export manually.","title":"2. Install poetry"},{"location":"contributing/installation/#3-install-the-neps-package-using-poetry","text":"Inside the main directory of neps run poetry install To install specific versions of torch (e.g., cuda enabled versions) you might want to use our utility python -m neps.utils.install_torch","title":"3. Install the neps Package Using poetry"},{"location":"contributing/installation/#4-activate-pre-commit-for-the-repository","text":"With the python environment used to install the neps package run in the main directory of neps pre-commit install","title":"4. Activate pre-commit for the repository"},{"location":"contributing/releasing/","text":"Releasing a New Version There are four steps to releasing a new version of neps: Understand Semantic Versioning Update the Package Version Commit and Push With a Version Tag Update Documentation Publish on PyPI 0. Understand Semantic Versioning We follow the semantic versioning scheme. 1. Update the Package Version poetry version v0.4.10 2. Commit with a Version Tag First commit and test git add pyproject.toml git commit -m \"Bump version from v0.4.9 to v0.4.10\" pytest Then tag and push git tag v0.4.10 git push --tags git push 3. Update Documentation First check if the documentation has any issues via mkdocs build mkdocs serve and then looking at it. Afterwards, publish it via mkdocs gh-deploy 4. Publish on PyPI To publish to PyPI: Get publishing rights, e.g., asking Danny or Maciej. Be careful, once on PyPI we can not change things. Run poetry publish --build This will ask for your PyPI credentials.","title":"Releasing a New Version"},{"location":"contributing/releasing/#releasing-a-new-version","text":"There are four steps to releasing a new version of neps: Understand Semantic Versioning Update the Package Version Commit and Push With a Version Tag Update Documentation Publish on PyPI","title":"Releasing a New Version"},{"location":"contributing/releasing/#0-understand-semantic-versioning","text":"We follow the semantic versioning scheme.","title":"0. Understand Semantic Versioning"},{"location":"contributing/releasing/#1-update-the-package-version","text":"poetry version v0.4.10","title":"1. Update the Package Version"},{"location":"contributing/releasing/#2-commit-with-a-version-tag","text":"First commit and test git add pyproject.toml git commit -m \"Bump version from v0.4.9 to v0.4.10\" pytest Then tag and push git tag v0.4.10 git push --tags git push","title":"2. Commit with a Version Tag"},{"location":"contributing/releasing/#3-update-documentation","text":"First check if the documentation has any issues via mkdocs build mkdocs serve and then looking at it. Afterwards, publish it via mkdocs gh-deploy","title":"3. Update Documentation"},{"location":"contributing/releasing/#4-publish-on-pypi","text":"To publish to PyPI: Get publishing rights, e.g., asking Danny or Maciej. Be careful, once on PyPI we can not change things. Run poetry publish --build This will ask for your PyPI credentials.","title":"4. Publish on PyPI"},{"location":"contributing/roadmap/","text":"Roadmap As soon as possible Features Python 3.8+ support Utility to get best HPs and (built) architecture Utility to get incumbent losses over time Fixes Metahyper Refine jobtimelimit feature Refactoring merge GP and hierarchical GP etc. Tests Add simple regression tests to run on each push Add comprehensive regression tests to run manually on the cluster on each version release Documentation Data reading example Working directory example Fill up the core documentation pages Before 1.0.0 version Features Seamless ddp via cli launcher (fix from Fabio / Sam) Finegrained control over HP user prior Incumbent plot Top vs all vs bottom distribution plots Tensorboard visualizations (incumbent plot, ..) Print search space upon run Fixes Printing architecture search spaces / search spaces in general Refactoring run_pipeline = evaluate_pipeline loss = validation_error remove constant parameter remove graph_dense API clean up search spaces classes, unused methods break up search space and config aspect Tests Clean up examples, create experimental examples and/or move examples for test-purposes to test dir Documentation Trunk based development techniques Point to smac for multi-objective problems and classic ML / have \"alternatives\" section in readme Changelog Later version Features Optional argparse adder like pytorch lightning Utility neps.clean to manage existing run results Collect data optionally via phone-home to webserver Add Info dict to status","title":"Roadmap"},{"location":"contributing/roadmap/#roadmap","text":"","title":"Roadmap"},{"location":"contributing/roadmap/#as-soon-as-possible","text":"","title":"As soon as possible"},{"location":"contributing/roadmap/#features","text":"Python 3.8+ support Utility to get best HPs and (built) architecture Utility to get incumbent losses over time","title":"Features"},{"location":"contributing/roadmap/#fixes","text":"Metahyper Refine jobtimelimit feature","title":"Fixes"},{"location":"contributing/roadmap/#refactoring","text":"merge GP and hierarchical GP etc.","title":"Refactoring"},{"location":"contributing/roadmap/#tests","text":"Add simple regression tests to run on each push Add comprehensive regression tests to run manually on the cluster on each version release","title":"Tests"},{"location":"contributing/roadmap/#documentation","text":"Data reading example Working directory example Fill up the core documentation pages","title":"Documentation"},{"location":"contributing/roadmap/#before-100-version","text":"","title":"Before 1.0.0 version"},{"location":"contributing/roadmap/#features_1","text":"Seamless ddp via cli launcher (fix from Fabio / Sam) Finegrained control over HP user prior Incumbent plot Top vs all vs bottom distribution plots Tensorboard visualizations (incumbent plot, ..) Print search space upon run","title":"Features"},{"location":"contributing/roadmap/#fixes_1","text":"Printing architecture search spaces / search spaces in general","title":"Fixes"},{"location":"contributing/roadmap/#refactoring_1","text":"run_pipeline = evaluate_pipeline loss = validation_error remove constant parameter remove graph_dense API clean up search spaces classes, unused methods break up search space and config aspect","title":"Refactoring"},{"location":"contributing/roadmap/#tests_1","text":"Clean up examples, create experimental examples and/or move examples for test-purposes to test dir","title":"Tests"},{"location":"contributing/roadmap/#documentation_1","text":"Trunk based development techniques Point to smac for multi-objective problems and classic ML / have \"alternatives\" section in readme Changelog","title":"Documentation"},{"location":"contributing/roadmap/#later-version","text":"","title":"Later version"},{"location":"contributing/roadmap/#features_2","text":"Optional argparse adder like pytorch lightning Utility neps.clean to manage existing run results Collect data optionally via phone-home to webserver Add Info dict to status","title":"Features"}]}