# Customizing NePS Searcher
run_pipeline:
  path: path/to/your/run_pipeline.py  # Path to the function file
  name: example_pipeline              # Function name within the file

pipeline_space:
  learning_rate:
    lower: 1e-5
    upper: 1e-1
    log: true  # Log scale for learning rate
  optimizer:
    choices: [adam, sgd, adamw]
  epochs: 50

root_directory: path/to/results       # Directory for result storage
max_evaluations_total: 20             # Budget
searcher:
  strategy: bayesian_optimization     # key for neps searcher
  name: "my_bayesian"                 # optional; changing the searcher_name for better recognition
  # Specific arguments depending on the searcher
  initial_design_size: 7
  surrogate_model: gp
  acquisition: EI
  acquisition_sampler: random
  random_interleave_prob: 0.1

