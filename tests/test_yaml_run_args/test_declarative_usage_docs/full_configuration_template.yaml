run_pipeline:
  path: path/to/your/run_pipeline.py  # Path to the function file
  name: example_run                   # Function name within the file

pipeline_space:
  learning_rate:
    lower: 1e-5
    upper: 1e-1
    log: True  # Log scale for learning rate
  optimizer:
    choices: [adam, sgd, adamw]
  epochs: 50

root_directory: path/to/results       # Directory for result storage
max_evaluations_total: 20               # Budget
max_cost_total:

# Debug and Monitoring
overwrite_working_directory: True
post_run_summary: True
development_stage_id:
task_id:

# parallelization_setup
max_evaluations_per_run:
continue_until_max_evaluation_completed: False

# error_handling
loss_value_on_error:
cost_value_on_error:
ignore_errors:

searcher: bayesian_optimization # To select only the searcher; for more options, see [here](#customizing-your-own-searcher).

pre_load_hooks:
