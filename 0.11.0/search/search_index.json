{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction and Installation","text":""},{"location":"#installation","title":"Installation","text":"<p>Using pip</p> <pre><code>pip install neural-pipeline-search\n</code></pre>"},{"location":"alternatives/","title":"Some Alternatives","text":"<ul> <li>SMAC</li> <li>Optuna</li> </ul>"},{"location":"analyse/","title":"Analysing Runs","text":"<p>NePS has some convenient utilities to help you to understand the results of your run.</p>"},{"location":"analyse/#saved-to-disk","title":"Saved to disk","text":"<p>In the root directory, NePS maintains several files at all times that are human readable and can be useful</p> <pre><code>ROOT_DIRECTORY\n\u251c\u2500\u2500 results\n\u2502  \u2514\u2500\u2500 config_1\n\u2502      \u251c\u2500\u2500 config.yaml\n\u2502      \u251c\u2500\u2500 metadata.yaml\n\u2502      \u2514\u2500\u2500 result.yaml\n\u251c\u2500\u2500 all_losses_and_configs.txt\n\u251c\u2500\u2500 best_loss_trajectory.txt\n\u2514\u2500\u2500 best_loss_with_config_trajectory.txt\n</code></pre>"},{"location":"analyse/#status","title":"Status","text":"<p>To show status information about a neural pipeline search run, use</p> <pre><code>python -m neps.status ROOT_DIRECTORY\n</code></pre> <p>If you need more status information than is printed per default (e.g., the best config over time), please have a look at</p> <pre><code>python -m neps.status --help\n</code></pre> <p>To show the status repeatedly, on unix systems you can use</p> <pre><code>watch --interval 30 python -m neps.status ROOT_DIRECTORY\n</code></pre>"},{"location":"analyse/#visualizations","title":"Visualizations","text":"<p>To generate plots to the root directory, run</p> <pre><code>python -m neps.plot ROOT_DIRECTORY\n</code></pre> <p>Currently, this creates one plot that shows the best error value across the number of evaluations.</p>"},{"location":"citations/","title":"Citation of The Software","text":"<p>For citing NePS, please refer to the following:</p>"},{"location":"citations/#apa-style","title":"APA Style","text":"<pre><code>Stoll, D., Mallik, N., Schrodi, S., Janowski, M., Garibov, S., Abou Chakra, T., Hvarfner, C., Bergman, E., Binxin, R., Kober, N., Vallaeys, T., &amp; Hutter, F. (2023). Neural Pipeline Search (NePS) (Version 0.10.0) [Computer software]. https://github.com/automl/neps\n</code></pre>"},{"location":"citations/#bibtex-style","title":"BibTex Style","text":"<pre><code>@software{Stoll_Neural_Pipeline_Search_2023,\nauthor = {Stoll, Danny and Mallik, Neeratyoy and Schrodi, Simon and Janowski, Maciej and Garibov, Samir and Abou Chakra, Tarek and Hvarfner, Carl and Bergman, Eddie and Binxin, Ru and Kober, Nils and Vallaeys, Th\u00e9ophane and Hutter, Frank},\nmonth = oct,\ntitle = {{Neural Pipeline Search (NePS)}},\nurl = {https://github.com/automl/neps},\nversion = {0.10.0},\nyear = {2023}\n}\n</code></pre>"},{"location":"citations/#citation-of-papers","title":"Citation of Papers","text":"<p>If you have used PriorBand as the optimizer, please use the bibtex below:</p>"},{"location":"citations/#priorband","title":"PriorBand","text":"<pre><code>@inproceedings{mallik2023priorband,\ntitle = {PriorBand: Practical Hyperparameter Optimization in the Age of Deep Learning},\nauthor = {Neeratyoy Mallik and Eddie Bergman and Carl Hvarfner and Danny Stoll and Maciej Janowski and Marius Lindauer and Luigi Nardi and Frank Hutter},\nyear = {2023},\nbooktitle = {Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS 2023)},\nkeywords = {}\n}\n</code></pre>"},{"location":"citations/#hierarchichal-nas-with-context-free-grammars","title":"Hierarchichal NAS with Context-free Grammars","text":"<p>If you have used the context-free grammar search space and the graph kernels implemented in NePS for the paper Hierarchical NAS, please use the bibtex below:</p> <pre><code>@inproceedings{schrodi2023hierarchical,\ntitle = {Construction of Hierarchical Neural Architecture Search Spaces based on Context-free Grammars},\nauthor = {Simon Schrodi and Danny Stoll and Binxin Ru and Rhea Sanjay Sukthanker and Thomas Brox and Frank Hutter},\nyear = {2023},\nbooktitle = {Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS 2023)},\nkeywords = {}\n}\n</code></pre>"},{"location":"parallelization/","title":"Parallelization","text":"<p>In order to run a neural pipeline search with multiple processes or multiple machines, simply call <code>neps.run</code> multiple times. All calls to <code>neps.run</code> need to use the same <code>root_directory</code> on the same filesystem, otherwise there is no synchronization between the <code>neps.run</code>'s.</p>"},{"location":"contributing/","title":"Introduction","text":""},{"location":"contributing/#getting-help","title":"Getting Help","text":"<p>Ask in the neps contributor chat on mattermost or any contributor directly. If you are not in the mattermost chat yet, ask to get access.</p>"},{"location":"contributing/#development-workflow","title":"Development Workflow","text":"<p>We loosely practice trunk-based-development:</p> <ul> <li>We work almost exclusively on the master branch</li> <li>We commit, push, and pull often</li> <li>We automatically run code quality checks before every commit (using pre-commit)</li> <li>We manually run tests (using <code>pytest</code>) before every critical push and automatically afterwards (using github actions)</li> </ul>"},{"location":"contributing/#installation","title":"Installation","text":"<p>For the contributor installation process see Installation.</p>"},{"location":"contributing/#checks-and-tests","title":"Checks and tests","text":"<p>The documentation also includes an overview on the protocols and tools we use for code quality checks and tests.</p>"},{"location":"contributing/dependencies/","title":"Managing Dependencies","text":"<p>To manage dependencies and for package distribution we use poetry (replaces pip).</p>"},{"location":"contributing/dependencies/#add-dependencies","title":"Add dependencies","text":"<p>To install a dependency use</p> <pre><code>poetry add dependency\n</code></pre> <p>and commit the updated <code>pyproject.toml</code> to git.</p> <p>For more advanced dependency management see examples in <code>pyproject.toml</code> or have a look at the poetry documentation.</p>"},{"location":"contributing/dependencies/#install-dependencies-added-by-others","title":"Install dependencies added by others","text":"<p>When other contributors added dependencies to <code>pyproject.toml</code>, you can install them via</p> <pre><code>poetry lock\npoetry install\n</code></pre>"},{"location":"contributing/documentation/","title":"Documentation","text":"<p>We use MkDocs, more specifically Material for MkDocs for documentation. To support documentation for multiple versions, we use the plugin mike. Source files for the documentation are at docs and configuration at  mkdocs.yml.</p> <p>To build and view the documentation run</p> <pre><code>mike deploy 0.5.1 latest\nmike serve\n</code></pre> <p>and open the URL shown by the <code>mike serve</code> command.</p> <p>To publish the documentation run</p> <pre><code>mike deploy 0.5.1 latest -p\n</code></pre>"},{"location":"contributing/installation/","title":"Installation for Contributors","text":"<p>There are three required steps and one optional:</p> <ol> <li>Optional: Install miniconda and create an environment</li> <li>Install poetry</li> <li>Install the neps package using poetry</li> <li>Activate pre-commit for the repository</li> </ol> <p>For instructions see below.</p>"},{"location":"contributing/installation/#1-optional-install-miniconda-and-create-an-environment","title":"1. Optional: Install miniconda and create an environment","text":"<p>To manage python versions install e.g., miniconda with</p> <pre><code>wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh -O install_miniconda.sh\nbash install_miniconda.sh -b -p $HOME/.conda  # Change to place of preference\nrm install_miniconda.sh\n</code></pre> <p>Consider running <code>~/.conda/bin/conda init</code> or <code>~/.conda/bin/conda init zsh</code> .</p> <p>Then finally create the environment and activate it</p> <pre><code>conda create -n neps python=3.10\nconda activate neps\n</code></pre>"},{"location":"contributing/installation/#2-install-poetry","title":"2. Install poetry","text":"<p>First, install poetry, e.g., via</p> <pre><code>curl -sSL https://install.python-poetry.org | python3 -\n</code></pre> <p>Then consider appending</p> <pre><code>export PATH=\"$HOME/.local/bin:$PATH\"\n</code></pre> <p>to your <code>.zshrc</code> / <code>.bashrc</code> or alternatively simply running the export manually.</p>"},{"location":"contributing/installation/#3-install-the-neps-package-using-poetry","title":"3. Install the neps Package Using poetry","text":"<p>Clone the repository, e.g.,</p> <pre><code>git clone https://github.com/automl/neps.git\ncd neps\n</code></pre> <p>Then, inside the main directory of neps run</p> <pre><code>poetry install\n</code></pre>"},{"location":"contributing/installation/#4-activate-pre-commit-for-the-repository","title":"4. Activate pre-commit for the repository","text":"<p>With the python environment used to install the neps package run in the main directory of neps</p> <pre><code>pre-commit install\n</code></pre>"},{"location":"contributing/releasing/","title":"Releasing a New Version","text":"<p>There are four steps to releasing a new version of neps:</p> <ol> <li>Understand Semantic Versioning</li> <li>Update the Package Version</li> <li>Commit and Push With a Version Tag</li> <li>Update Documentation</li> <li>Publish on PyPI</li> </ol>"},{"location":"contributing/releasing/#0-understand-semantic-versioning","title":"0. Understand Semantic Versioning","text":"<p>We follow the semantic versioning scheme.</p>"},{"location":"contributing/releasing/#1-update-the-package-version-and-citationcff","title":"1. Update the Package Version and CITATION.cff","text":"<pre><code>poetry version v0.9.0\n</code></pre> <p>and manually change the version specified in <code>CITATION.cff</code>.</p>"},{"location":"contributing/releasing/#2-commit-with-a-version-tag","title":"2. Commit with a Version Tag","text":"<p>First commit and test</p> <pre><code>git add pyproject.toml\ngit commit -m \"Bump version from v0.8.4 to v0.9.0\"\npytest\n</code></pre> <p>Then tag and push</p> <pre><code>git tag v0.9.0\ngit push --tags\ngit push\n</code></pre>"},{"location":"contributing/releasing/#3-update-documentation","title":"3. Update Documentation","text":"<p>First check if the documentation has any issues via</p> <pre><code>mike deploy 0.9.0 latest -u\nmike serve\n</code></pre> <p>and then looking at it.</p> <p>Afterwards, publish it via</p> <pre><code>mike deploy 0.9.0 latest -up\n</code></pre>"},{"location":"contributing/releasing/#4-publish-on-pypi","title":"4. Publish on PyPI","text":"<p>To publish to PyPI:</p> <ol> <li>Get publishing rights, e.g., asking Danny or Maciej or Neeratyoy.</li> <li>Be careful, once on PyPI we can not change things.</li> <li>Run</li> </ol> <pre><code>poetry publish --build\n</code></pre> <p>This will ask for your PyPI credentials.</p>"},{"location":"contributing/roadmap/","title":"Roadmap","text":""},{"location":"contributing/roadmap/#before-0120","title":"Before 0.12.0","text":""},{"location":"contributing/roadmap/#features","title":"Features","text":"<ul> <li>Allow yaml based input of search space and the target function source to <code>neps.run</code></li> <li>Generate plot after each evaluation</li> <li>Support conditionals in ConfigSpace search space</li> <li>Support logging of optimizer state details</li> </ul>"},{"location":"contributing/roadmap/#fixes","title":"Fixes","text":"<ul> <li>Open never closes (talk to Nils)</li> <li>Deadlock in ASHA-like optimizers (talk to Neeratyoy)</li> <li>Extra metahyper sample in issue 42</li> <li>Tighter type check in search space</li> <li>Unify MFObservedData class for both Hyperband-like fidelities and one-step fidelities</li> </ul>"},{"location":"contributing/roadmap/#documentation","title":"Documentation","text":"<ul> <li>Improved documentation on all basic usage</li> <li>Improved README on github that links to the documentations</li> <li>Adequate examples targeting different user groups</li> </ul>"},{"location":"contributing/roadmap/#refactoring","title":"Refactoring","text":"<ul> <li>Merge GP and hierarchical GP</li> <li>Merge gpytorch branch</li> <li>Rethink summary/status API</li> <li>Improve placement of _post_evaluation_hook_function</li> <li>maintained vs unmaintained optimizers</li> <li>Read and sample at the same time metahyper</li> <li>Metahyper into neps</li> <li>Renamings</li> <li>run_pipeline = evaluate_pipeline | evaluate_pipeline_error | compute_pipeline_error | train_and_evaluate</li> <li>loss = validation_error | error | pipeline_error</li> <li>XParameter = XSpace</li> <li>Rename default-x to prior-x</li> <li>Use max_cost_total everywhere instead of budget</li> </ul>"},{"location":"contributing/roadmap/#tests-and-tooling","title":"Tests and tooling","text":"<ul> <li>Add priorband to experimental</li> <li>Add simple regression tests to run on each push</li> </ul>"},{"location":"contributing/roadmap/#before-100-version","title":"Before 1.0.0 version","text":""},{"location":"contributing/roadmap/#features_1","title":"Features","text":"<ul> <li>Seamless ddp via cli launcher</li> <li>Finegrained control over HP user prior</li> <li>Top vs all vs bottom distribution plots</li> <li>Tensorboard visualizations (incumbent plot, ..)</li> <li>Loss distribution plot</li> <li>Print search space upon run</li> <li>Add comprehensive regression tests to run manually on the cluster on each version release</li> <li>Utility to generate code for best architecture</li> <li>Core Feature set in terms of research</li> <li>Modular plug-and-play of BoTorch acquisition functions</li> <li>Exploring gradient-based HPO in the NePS framework</li> </ul>"},{"location":"contributing/roadmap/#fixes_1","title":"Fixes","text":"<ul> <li>Printing architecture search spaces / search spaces in general</li> <li>Metahyper Refine jobtimelimit feature</li> <li>Optimize dependencies</li> </ul>"},{"location":"contributing/roadmap/#refactoring_1","title":"Refactoring","text":"<ul> <li>Clean up search spaces classes, unused methods</li> <li>Break up search space and config aspect</li> <li>Remove hnas branch</li> <li>Refactor of constraint grammar</li> </ul>"},{"location":"contributing/roadmap/#documentation_1","title":"Documentation","text":"<ul> <li>Keep a changelog</li> </ul>"},{"location":"contributing/roadmap/#later-version","title":"Later version","text":""},{"location":"contributing/roadmap/#features_2","title":"Features","text":"<ul> <li>neps_examples callable for options of examples</li> <li>Optional argparse adder like pytorch lightning</li> <li>Utility neps.clean to manage existing run results</li> <li>Collect data optionally via phone-home to webserver</li> <li>Add Info dict to status</li> <li>Seed (setting context manager?)</li> <li>BO improvements via Hebo tricks + Mll replacement</li> <li>Checkout Rich logging</li> </ul>"},{"location":"contributing/roadmap/#miscellaneous","title":"Miscellaneous","text":"<ul> <li>User Mattermost Channel</li> <li>Twitter handle and domain, e.g., neural-pipeline.search</li> <li>Doing research with NePS / Documentation on that or full setup</li> </ul>"},{"location":"contributing/tests/","title":"Checks and Tests","text":"<p>We have setup checks and tests at several points in the development flow:</p> <ul> <li>At every commit we automatically run a suite of pre-commit hooks that perform static code analysis, autoformating, and sanity checks. This is setup during our installation process.</li> <li>At every commit / push locally running a minimal suite of integration tests is encouraged. The tests correspond directly to examples in neps_examples and only check for crash-causing errors.</li> <li>At every push all integration tests and regression tests are run automatically using github actions.</li> </ul>"},{"location":"contributing/tests/#examples-and-integration-tests","title":"Examples and Integration Tests","text":"<p>We use examples in neps_examples as integration tests, which we run from the main directory via</p> <pre><code>pytest\n</code></pre> <p>before every critical push.</p>"},{"location":"contributing/tests/#creating-an-integration-test","title":"Creating an Integration Test","text":"<p>If you want an implementation to be included in the above testing procedure:</p> <ol> <li>Create an example in neps_examples.</li> <li>Add the example to test_examples.py.</li> </ol>"},{"location":"contributing/tests/#running-all-integration-tests-locally","title":"Running all integration tests locally","text":"<p>To speedup testing for developers, we only run a core set of tests per default. To run all tests use</p> <pre><code>pytest -m all_examples\n</code></pre> <p>On github, we always run all examples.</p>"},{"location":"contributing/tests/#what-to-do-if-tests-fail","title":"What to do if tests fail","text":"<p>If tests fail for you on the master:</p> <ol> <li>Try running the tests with a fresh environment install.</li> <li>If issues persist, notify others in the neps developers chat on mattermost.</li> </ol>"},{"location":"contributing/tests/#regression-tests","title":"Regression Tests","text":"<p>Regression tests are run on each push to the repository to assure the performance of the optimizers don't degrade.</p> <p>Currently, regression runs are recorded on JAHS-Bench-201 data for 2 tasks: <code>cifar10</code> and <code>fashion_mnist</code> and only for optimizers: <code>random_search</code>, <code>bayesian_optimization</code>, <code>mf_bayesian_optimization</code>, <code>regularized_evolution</code>. This information is stored in the <code>tests/regression_runner.py</code> as two lists: <code>TASKS</code>, <code>OPTIMIZERS</code>. The recorded results are stored as a json dictionary in the <code>tests/losses.json</code> file.</p>"},{"location":"contributing/tests/#adding-new-optimizer-algorithms","title":"Adding new optimizer algorithms","text":"<p>Once a new algorithm is added to NEPS library, we need to first record the performance of the algorithm for 100 optimization runs.</p> <ul> <li> <p>If the algorithm expects standard loss function (pipeline) and accepts fidelity hyperparameters in pipeline space, then recording results only requires adding the optimizer name into <code>OPTIMIZERS</code> list in <code>tests/regression_runner.py</code> and running <code>tests/regression_runner.py</code></p> </li> <li> <p>In case your algorithm requires custom pipeline and/or pipeline space you can modify the <code>runner.run_pipeline</code> and <code>runner.pipeline_space</code> attributes of the <code>RegressionRunner</code> after initialization (around line <code>#322</code> in <code>tests/regression_runner.py</code>)</p> </li> </ul> <p>You can verify the optimizer is recorded by rerunning the <code>regression_runner.py</code>. Now regression test will be run on your new optimizer as well on every push.</p>"},{"location":"contributing/tests/#regression-test-metrics","title":"Regression test metrics","text":"<p>For each regression test the algorithm is run 10 times to sample its performance, then they are statistically compared to the 100 recorded runs. We use these 3 boolean metrics to define the performance of the algorithm on any task:</p> <ol> <li>Kolmogorov-Smirnov test for goodness of fit - <code>pvalue</code> &gt;= 10%</li> <li>Absolute median distance - bounded within 92.5% confidence range of the expected median distance</li> <li>Median improvement - Median improvement over the recorded median</li> </ol> <p>Test metrics are run for each <code>(optimizer, task)</code> combination separately and then collected. The collected metrics are then further combined into 2 metrics</p> <ol> <li>Task pass - either both <code>Kolmogorov-Smirnov test</code> and <code>Absolute median distance</code> test passes or just <code>Median improvement</code></li> <li>Test aggregate - Sum_over_tasks(<code>Kolmogorov-Smirnov test</code> + <code>Absolute median distance</code> + 2 * <code>Median improvement</code>)</li> </ol> <p>Finally, a test for an optimizer only passes when at least for one of the tasks <code>Task pass</code> is true, and <code>Test aggregate</code> is higher than 1 + <code>number of tasks</code></p>"},{"location":"contributing/tests/#on-regression-test-failures","title":"On regression test failures","text":"<p>Regression tests are stochastic by nature, so they might fail occasionally even the algorithm performance didn't degrade. In the case of regression test failure, try running it again first, if the problem still persists, then you can contact Danny Stoll or Samir. You can also run tests locally by running:</p> <pre><code>poetry run pytest -m regression_all\n</code></pre>"},{"location":"contributing/tests/#disabling-and-skipping-checks-etc","title":"Disabling and Skipping Checks etc.","text":""},{"location":"contributing/tests/#pre-commit-how-to-not-run-hooks","title":"Pre-commit: How to not run hooks?","text":"<p>To commit without running <code>pre-commit</code> use <code>git commit --no-verify -m &lt;COMMIT MESSAGE&gt;</code>.</p>"},{"location":"contributing/tests/#pylint-how-to-ignore-warnings","title":"Pylint: How to ignore warnings?","text":"<p>There are two options:</p> <ul> <li>Disable the warning locally:</li> </ul> <pre><code>code = \"foo\"  # pylint: disable=ERROR_CODE\n</code></pre> <p>Make sure to use the named version of the error (e.g., <code>unspecified-encoding</code>, not <code>W1514</code>).</p> <ul> <li>Remove warning in <code>pyproject.toml</code> that we do not consider useful (do not catch bugs, do not increase code quality).</li> </ul>"},{"location":"contributing/tests/#mypy-how-to-ignore-warnings","title":"Mypy: How to ignore warnings?","text":"<p>There are two options:</p> <ul> <li>Disable the warning locally:</li> </ul> <pre><code>code = \"foo\"  # type: ignore[ERROR_CODE]\n</code></pre> <ul> <li>If you know what you are doing, you can add the whole module to the <code>[[tool.mypy.overrides]]</code> section.   This is useful e.g., when adding new files that are in early stage development.</li> </ul>"},{"location":"contributing/tests/#black-how-to-not-format-code-parts","title":"Black: How to not format code parts?","text":"<pre><code>x = 2  # fmt: off\n</code></pre> <p>or for blocks</p> <pre><code># fmt: off\nx = 2\ny = x + 1\n# fmt: on\n</code></pre>"}]}