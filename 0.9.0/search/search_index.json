{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Neural Pipeline Search (NePS)","text":"<p>Welcome to NePS, a powerful and flexible Python library for hyperparameter optimization (HPO) and neural architecture search (NAS) with its primary goal: enable HPO adoption in practice for deep learners!</p> <p>NePS houses recently published and some more well-established algorithms that are all capable of being run massively parallel on any distributed setup, with tools to analyze runs, restart runs, etc.</p>"},{"location":"#key-features","title":"Key Features","text":"<p>In addition to the common features offered by traditional HPO and NAS libraries, NePS stands out with the following key features:</p> <ol> <li> <p>Hyperparameter Optimization (HPO) With Prior Knowledge:</p> <ul> <li>NePS excels in efficiently tuning hyperparameters using algorithms that enable users to make use of their prior knowledge within the search space. This is leveraged by the insights presented in:<ul> <li>PriorBand: Practical Hyperparameter Optimization in the Age of Deep Learning</li> <li>\u03c0BO: Augmenting Acquisition Functions with User Beliefs for Bayesian Optimization</li> </ul> </li> </ul> </li> <li> <p>Neural Architecture Search (NAS) With Context-free Grammar Search Spaces:</p> <ul> <li>NePS is equipped to handle context-free grammar search spaces, providing advanced capabilities for designing and optimizing architectures. this is leveraged by the insights presented in:<ul> <li>Construction of Hierarchical Neural Architecture Search Spaces based on Context-free Grammars</li> </ul> </li> </ul> </li> <li> <p>Easy Parallelization and Resumption of Runs:</p> <ul> <li>NePS simplifies the process of parallelizing optimization tasks both on individual computers and in distributed    computing environments. It also allows users to conveniently resume these optimization tasks after completion to    ensure a seamless and efficient workflow for long-running experiments.</li> </ul> </li> <li> <p>Seamless User Code Integration:</p> <ul> <li>NePS's modular design ensures flexibility and extensibility. Integrate NePS effortlessly into existing machine learning workflows.</li> </ul> </li> </ol>"},{"location":"alternatives/","title":"Some Alternatives","text":"<ul> <li>SMAC</li> <li>Optuna</li> </ul>"},{"location":"analyse/","title":"Analysing Runs","text":"<p>NePS has some convenient utilities to help you to understand the results of your run.</p>"},{"location":"analyse/#saved-to-disk","title":"Saved to disk","text":"<p>In the root directory, NePS maintains several files at all times that are human readable and can be useful</p> <pre><code>ROOT_DIRECTORY\n\u251c\u2500\u2500 results\n\u2502  \u2514\u2500\u2500 config_1\n\u2502      \u251c\u2500\u2500 config.yaml\n\u2502      \u251c\u2500\u2500 metadata.yaml\n\u2502      \u2514\u2500\u2500 result.yaml\n\u251c\u2500\u2500 all_losses_and_configs.txt\n\u251c\u2500\u2500 best_loss_trajectory.txt\n\u2514\u2500\u2500 best_loss_with_config_trajectory.txt\n</code></pre>"},{"location":"analyse/#summary-csv","title":"Summary CSV","text":"<p>The argument <code>post_run_summary</code> in <code>neps.run</code> allows for the automatic generation of CSV files after a run is complete. The new root directory after utilizing this argument will look like the following:</p> <pre><code>ROOT_DIRECTORY\n\u251c\u2500\u2500 results\n\u2502  \u2514\u2500\u2500 config_1\n\u2502      \u251c\u2500\u2500 config.yaml\n\u2502      \u251c\u2500\u2500 metadata.yaml\n\u2502      \u2514\u2500\u2500 result.yaml\n\u251c\u2500\u2500 summary_csv\n\u2502  \u251c\u2500\u2500 config_data.csv\n\u2502  \u2514\u2500\u2500 run_status.csv\n\u251c\u2500\u2500 all_losses_and_configs.txt\n\u251c\u2500\u2500 best_loss_trajectory.txt\n\u2514\u2500\u2500 best_loss_with_config_trajectory.txt\n</code></pre> <ul> <li> <p><code>config_data.csv</code>: Contains all configuration details in CSV format, ordered by ascending <code>loss</code>. Details include configuration hyperparameters, any returned result from the <code>run_pipeline</code> function, and metadata information.</p> </li> <li> <p><code>run_status.csv</code>: Provides general run details, such as the number of sampled configs, best configs, number of failed configs, best loss, etc.</p> </li> </ul>"},{"location":"analyse/#tensorboard-integration","title":"TensorBoard Integration","text":""},{"location":"analyse/#introduction","title":"Introduction","text":"<p>TensorBoard serves as a valuable tool for visualizing machine learning experiments, offering the ability to observe losses and metrics throughout the model training process. In NePS, we use this powerful tool to show metrics of configurations during training in addition to comparisons to different hyperparameters used in the search for better diagnosis of the model.</p>"},{"location":"analyse/#the-logging-function","title":"The Logging Function","text":"<p>The <code>tblogger.log</code> function is invoked within the model's training loop to facilitate logging of key metrics.</p> <p>Tip</p> <p>The logger function is primarily designed for implementation within the <code>run_pipeline</code> function during the training of the neural network.</p> <ul> <li> <p>Signature: <pre><code>tblogger.log(\n    loss: float,\n    current_epoch: int,\n    write_config_scalar: bool = False,\n    write_config_hparam: bool = True,\n    write_summary_incumbent: bool = False,\n    extra_data: dict | None = None\n)\n</code></pre></p> </li> <li> <p>Parameters:</p> <ul> <li><code>loss</code> (float): The loss value to be logged.</li> <li><code>current_epoch</code> (int): The current epoch or iteration number.</li> <li><code>write_config_scalar</code> (bool, optional): Set to <code>True</code> for a live loss trajectory for each configuration.</li> <li><code>write_config_hparam</code> (bool, optional): Set to <code>True</code> for live parallel coordinate, scatter plot matrix, and table view.</li> <li><code>write_summary_incumbent</code> (bool, optional): Set to <code>True</code> for a live incumbent trajectory.</li> <li><code>extra_data</code> (dict, optional): Additional data to be logged, provided as a dictionary.</li> </ul> </li> </ul>"},{"location":"analyse/#extra-custom-logging","title":"Extra Custom Logging","text":"<p>NePS provides dedicated functions for customized logging using the <code>extra_data</code> argument. </p> <p>Custom Logging Instructions</p> <p>Name the dictionary keys as the names of the values you want to log and pass one of the following functions as the values for a successful logging process.</p>"},{"location":"analyse/#1-extra-scalar-logging","title":"1- Extra Scalar Logging","text":"<p>Logs new scalar data during training. Uses <code>current_epoch</code> from the log function as its <code>global_step</code>.</p> <ul> <li>Signature: <pre><code>tblogger.scalar_logging(value: float)\n</code></pre></li> <li>Parameters:<ul> <li><code>value</code> (float): Any scalar value to be logged at the current epoch of <code>tblogger.log</code> function.</li> </ul> </li> </ul>"},{"location":"analyse/#2-extra-image-logging","title":"2- Extra Image Logging","text":"<p>Logs images during training. Images can be resized, randomly selected, and a specified number can be logged at specified intervals. Uses <code>current_epoch</code> from the log function as its <code>global_step</code>.</p> <ul> <li> <p>Signature: <pre><code>tblogger.image_logging(\n    image: torch.Tensor,\n    counter: int = 1,\n    resize_images: list[None | int] | None = None,\n    random_images: bool = True,\n    num_images: int = 20,\n    seed: int | np.random.RandomState | None = None,\n)\n</code></pre></p> </li> <li> <p>Parameters:</p> <ul> <li><code>image</code> (torch.Tensor): Image tensor to be logged.</li> <li><code>counter</code> (int): Log images every counter epochs (i.e., when current_epoch % counter equals 0).</li> <li><code>resize_images</code> (list of int, optional): List of integers for image sizes after resizing (default: [32, 32]).</li> <li><code>random_images</code> (bool, optional): Images are randomly selected if True (default: True).</li> <li><code>num_images</code> (int, optional): Number of images to log (default: 20).</li> <li><code>seed</code> (int or np.random.RandomState or None, optional): Seed value or RandomState instance to control randomness and reproducibility (default: None).</li> </ul> </li> </ul>"},{"location":"analyse/#logging-example","title":"Logging Example","text":"<p>For illustration purposes, we have employed a straightforward example involving the tuning of hyperparameters for a model utilized in the classification of the MNIST dataset provided by torchvision.</p> <p>You can find this example here</p> <p>Important</p> <p>We have optimized the example for computational efficiency. If you wish to replicate the exact results showcased in the following section, we recommend the following modifications:</p> <p>1- Increase maximum epochs from 2 to 10</p> <p>2- Set the <code>write_summary_incumbent</code> argument to <code>True</code></p> <p>3- Change the searcher from <code>random_search</code> to <code>bayesian_optimization</code></p> <p>4- Increase the maximum evaluations before disabling <code>tblogger</code> from 2 to 14</p> <p>5- Increase the maximum evaluations after disabling <code>tblogger</code> from 3 to 15</p>"},{"location":"analyse/#visualization-results","title":"Visualization Results","text":"<p>The following command will open a local host for TensorBoard visualizations, allowing you to view them either in real-time or after the run is complete.</p> <pre><code>tensorboard --logdir path/to/root_directory\n</code></pre> <p>This image shows visualizations related to scalar values logged during training. Scalars typically include metrics such as loss, incumbent trajectory, a summary of losses for all configurations, and any additional data provided via the <code>extra_data</code> argument in the <code>tblogger.log</code> function. </p> <p></p> <p>This image represents visualizations related to logged images during training. It could include snapshots of input data, model predictions, or any other image-related information. In our case, we use images to depict instances of incorrect predictions made by the model.</p> <p></p> <p>The following images showcase visualizations related to hyperparameter logging in TensorBoard. These plots include three different views, providing insights into the relationship between different hyperparameters and their impact on the model.</p> <p>In the table view, you can explore hyperparameter configurations across five different trials. The table displays various hyperparameter values alongside corresponding evaluation metrics.</p> <p></p> <p>The parallel coordinate plot offers a holistic perspective on hyperparameter configurations. By presenting multiple hyperparameters simultaneously, this view allows you to observe the interactions between variables, providing insights into their combined influence on the model.</p> <p></p> <p>The scatter plot matrix view provides an in-depth analysis of pairwise relationships between different hyperparameters. By visualizing correlations and patterns, this view aids in identifying key interactions that may influence the model's performance.</p> <p></p>"},{"location":"analyse/#status","title":"Status","text":"<p>To show status information about a neural pipeline search run, use</p> <pre><code>python -m neps.status ROOT_DIRECTORY\n</code></pre> <p>If you need more status information than is printed per default (e.g., the best config over time), please have a look at</p> <pre><code>python -m neps.status --help\n</code></pre> <p>To show the status repeatedly, on unix systems you can use</p> <pre><code>watch --interval 30 python -m neps.status ROOT_DIRECTORY\n</code></pre>"},{"location":"analyse/#cli-commands","title":"CLI commands","text":"<p>To generate plots to the root directory, run</p> <pre><code>python -m neps.plot ROOT_DIRECTORY\n</code></pre> <p>Currently, this creates one plot that shows the best error value across the number of evaluations.</p>"},{"location":"citations/","title":"Citations","text":""},{"location":"citations/#citation-of-the-software","title":"Citation of The Software","text":"<p>For citing NePS, please refer to the following:</p>"},{"location":"citations/#apa-style","title":"APA Style","text":"<pre><code>Stoll, D., Mallik, N., Schrodi, S., Janowski, M., Garibov, S., Abou Chakra, T., Rogalla, D., Bergman, E., Hvarfner, C., Binxin, R., Kober, N., Vallaeys, T., &amp; Hutter, F. (2023). Neural Pipeline Search (NePS) (Version 0.11.0) [Computer software]. https://github.com/automl/neps\n</code></pre>"},{"location":"citations/#bibtex-style","title":"BibTex Style","text":"<pre><code>@software{Stoll_Neural_Pipeline_Search_2023,\nauthor = {Stoll, Danny and Mallik, Neeratyoy and Schrodi, Simon and Janowski, Maciej and Garibov, Samir and Abou Chakra, Tarek and Rogalla, Daniel and Bergman, Eddie and Hvarfner, Carl and Binxin, Ru and Kober, Nils and Vallaeys, Th\u00e9ophane and Hutter, Frank},\nmonth = oct,\ntitle = {{Neural Pipeline Search (NePS)}},\nurl = {https://github.com/automl/neps},\nversion = {0.11.0},\nyear = {2023}\n}\n</code></pre>"},{"location":"citations/#citation-of-papers","title":"Citation of Papers","text":""},{"location":"citations/#priorband","title":"PriorBand","text":"<p>If you have used PriorBand as the optimizer, please use the bibtex below:</p> <pre><code>@inproceedings{mallik2023priorband,\ntitle = {PriorBand: Practical Hyperparameter Optimization in the Age of Deep Learning},\nauthor = {Neeratyoy Mallik and Eddie Bergman and Carl Hvarfner and Danny Stoll and Maciej Janowski and Marius Lindauer and Luigi Nardi and Frank Hutter},\nyear = {2023},\nbooktitle = {Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS 2023)},\nkeywords = {}\n}\n</code></pre>"},{"location":"citations/#hierarchichal-nas-with-context-free-grammars","title":"Hierarchichal NAS with Context-free Grammars","text":"<p>If you have used the context-free grammar search space and the graph kernels implemented in NePS for the paper Hierarchical NAS, please use the bibtex below:</p> <pre><code>@inproceedings{schrodi2023hierarchical,\ntitle = {Construction of Hierarchical Neural Architecture Search Spaces based on Context-free Grammars},\nauthor = {Simon Schrodi and Danny Stoll and Binxin Ru and Rhea Sanjay Sukthanker and Thomas Brox and Frank Hutter},\nyear = {2023},\nbooktitle = {Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS 2023)},\nkeywords = {}\n}\n</code></pre>"},{"location":"getting_started/","title":"Getting Started","text":"<p>Getting started with NePS involves a straightforward yet powerful process, centering around its three main components. This approach ensures flexibility and efficiency in evaluating different architecture and hyperparameter configurations for your problem.</p>"},{"location":"getting_started/#the-3-main-components","title":"The 3 Main Components","text":"<ol> <li> <p>Define a <code>run_pipeline</code> Function: This function is essential for evaluating different configurations. You'll implement the specific logic for your problem within this function. For detailed instructions on initializing and effectively using <code>run_pipeline</code>, refer to the guide.</p> </li> <li> <p>Establish a <code>pipeline_space</code>: Your search space for defining parameters. You can structure this in various formats, including dictionaries, YAML, or ConfigSpace. The guide offers insights into defining and configuring your search space.</p> </li> <li> <p>Execute with <code>neps.run</code>: Optimize your <code>run_pipeline</code> over the <code>pipeline_space</code> using this function. For a thorough overview of the arguments and their explanations, check out the detailed documentation.</p> </li> </ol> <p>By following these steps and utilizing the extensive resources provided in the guides, you can tailor NePS to meet your specific requirements, ensuring a streamlined and effective optimization process.</p>"},{"location":"getting_started/#basic-usage","title":"Basic Usage","text":"<p>In code, the usage pattern can look like this:</p> <pre><code>import neps\nimport logging\n\n\n# 1. Define a function that accepts hyperparameters and computes the validation error\ndef run_pipeline(\n    hyperparameter_a: float, hyperparameter_b: int, architecture_parameter: str\n) -&gt; dict:\n    # insert here your own model\n    model = MyModel(architecture_parameter)\n\n    # insert here your training/evaluation pipeline\n    validation_error, training_error = train_and_eval(\n        model, hyperparameter_a, hyperparameter_b\n    )\n\n    return {  # dict or float(validation error)\n        \"loss\": validation_error,\n        \"info_dict\": {\n            \"training_error\": training_error\n            # + Other metrics\n        },\n    }\n\n\n# 2. Define a search space of the parameters of interest; ensure that the names are consistent with those defined\n# in the run_pipeline function\npipeline_space = dict(\n    hyperparameter_b=neps.IntegerParameter(\n        lower=1, upper=42, is_fidelity=True\n    ),  # Mark 'is_fidelity' as true for a multi-fidelity approach.\n    hyperparameter_a=neps.FloatParameter(\n        lower=0.001, upper=0.1, log=True\n    ),  # If True, the search space is sampled in log space.\n    architecture_parameter=neps.CategoricalParameter(\n        [\"option_a\", \"option_b\", \"option_c\"]\n    ),\n)\n\nif __name__ == \"__main__\":\n    # 3. Run the NePS optimization\n    logging.basicConfig(level=logging.INFO)\n    neps.run(\n        run_pipeline=run_pipeline,\n        pipeline_space=pipeline_space,\n        root_directory=\"path/to/save/results\",  # Replace with the actual path.\n        max_evaluations_total=100,\n        searcher=\"hyperband\"  # Optional specifies the search strategy,\n        # otherwise NePs decides based on your data.\n    )\n</code></pre>"},{"location":"getting_started/#examples","title":"Examples","text":"<p>Discover the features of NePS through these practical examples:</p> <ul> <li> <p>Hyperparameter Optimization (HPO): Learn the essentials of hyperparameter optimization with NePS.</p> </li> <li> <p>Architecture Search with Primitives: Dive into architecture search using primitives in NePS.</p> </li> <li> <p>Multi-Fidelity Optimization: Understand how to leverage multi-fidelity optimization for efficient model tuning.</p> </li> <li> <p>Utilizing Expert Priors for Hyperparameters: Learn how to incorporate expert priors for more efficient hyperparameter selection.</p> </li> <li> <p>Additional NePS Examples: Explore more examples, including various use cases and advanced configurations in NePS.</p> </li> </ul>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#prerequisites","title":"Prerequisites","text":"<p>Ensure you have Python version 3.8, 3.9, 3.10, or 3.11 installed. NePS installation will automatically handle any additional dependencies via pip.</p>"},{"location":"installation/#install-from-pip","title":"Install from pip","text":"<pre><code>pip install neural-pipeline-search\n</code></pre> <p>Note: As indicated with the <code>v0.x.x</code> version number, NePS is early stage code and APIs might change in the future.</p>"},{"location":"installation/#install-from-source","title":"Install from source","text":"<p>Note</p> <p>We use poetry to manage dependecies.</p> <pre><code>git clone https://github.com/automl/neps.git\ncd neps\npoetry install --no-dev\n</code></pre>"},{"location":"neps_run/","title":"Configuring and Running Optimizations","text":"<p>The <code>neps.run</code> function is the core of the NePS optimization process, where the search for the best hyperparameters and architectures takes place. This document outlines the arguments and options available within this function, providing a detailed guide to customize the optimization process to your specific needs.</p>"},{"location":"neps_run/#search-strategy","title":"Search Strategy","text":"<p>At default NePS intelligently selects the most appropriate search strategy based on your defined configurations in <code>pipeline_space</code>. The characteristics of your search space, as represented in the <code>pipeline_space</code>, play a crucial role in determining which optimizer NePS will choose. This automatic selection process ensures that the strategy aligns perfectly with the specific requirements and nuances of your search space, thereby optimizing the effectiveness of the hyperparameter and/or architecture optimization. You can also manually select a specific or custom optimizer that better matches your specific needs. For more information, refer here.</p>"},{"location":"neps_run/#arguments","title":"Arguments","text":""},{"location":"neps_run/#mandatory-arguments","title":"Mandatory Arguments","text":"<ul> <li><code>run_pipeline</code> (function): The objective function, targeted by NePS for minimization, by evaluation various   configurations. It requires these configurations as input and should return either a dictionary or a sole loss   value as the output. For correct setup instructions, refer to here</li> <li> <p><code>pipeline_space</code> (dict | yaml | configspace): This defines the search space for the configurations from which the   optimizer samples. It accepts either a dictionary with the configuration names as keys, a path to a YAML   configuration file, or a configSpace.ConfigurationSpace object. For comprehensive information and examples,   please refer to the detailed guide available here</p> </li> <li> <p><code>root_directory</code> (str): The directory path where the information about the optimization and its progress gets   stored. This is also used to synchronize multiple calls to run(.) for parallelization.</p> </li> <li> <p>Budget: To define a budget, provide either or both of the following parameters:</p> <ul> <li><code>max_evaluations_total</code> (int, default: None): Specifies the total number of evaluations to conduct before   halting the optimization process.</li> <li><code>max_cost_total</code> (int, default: None): Prevents the initiation of new evaluations once this cost   threshold is surpassed. This requires adding a cost value to the output of the <code>run_pipeline</code> function,   for example, return {'loss': loss, 'cost': cost}. For more details, please refer   here</li> </ul> </li> </ul>"},{"location":"neps_run/#optional-arguments","title":"Optional Arguments","text":""},{"location":"neps_run/#further-monitoring-options","title":"Further Monitoring Options","text":"<ul> <li><code>overwrite_working_directory</code> (bool, default: False): When set to True, the working directory     specified by     <code>root_directory</code> will be     cleared at the beginning of the run. This is e.g. useful when debugging a <code>run_pipeline</code> function.</li> <li><code>post_run_summary</code> (bool, default: False): When enabled, this option generates a summary CSV file     upon the     completion of the     optimization process. The summary includes details of the optimization procedure, such as the best configuration,     the number of errors occurred, and the final performance metrics.</li> <li><code>development_stage_id</code> (int | float | str, default: None): An optional identifier used when working with     multiple development stages. Instead of creating new root directories, use this identifier to save the results     of an optimization run in a separate dev_id folder within the root_directory.</li> <li><code>task_id</code> (int | float | str, default: None): An optional identifier used when the optimization process     involves multiple tasks. This functions similarly to <code>development_stage_id</code>, but it creates a folder named     after the task_id instead of dev_id, providing an organized way to separate results for different tasks within     the <code>root_directory</code>.</li> </ul>"},{"location":"neps_run/#parallelization-setup","title":"Parallelization Setup","text":"<ul> <li><code>max_evaluations_per_run</code> (int, default: None): Limits the number of evaluations for this specific call of     <code>neps.run</code>.</li> <li><code>continue_until_max_evaluation_completed</code> (bool, default: False): In parallel setups, pending evaluations     normally count towards max_evaluations_total, halting new ones when this limit is reached. Setting this to     True enables continuous sampling of new evaluations until the total of completed ones meets max_evaluations_total,     optimizing resource use in time-sensitive scenarios.</li> </ul> <p>For an overview and further resources on how NePS supports parallelization in distributed systems, refer to the Parallelization Overview.</p>"},{"location":"neps_run/#handling-errors","title":"Handling Errors","text":"<ul> <li><code>loss_value_on_error</code> (float, default: None): When set, any error encountered in an evaluated configuration     will not halt the process; instead, the specified loss value will be used for that configuration.</li> <li><code>cost_value_on_error</code> (float, default: None): Similar to <code>loss_value_on_error</code>, but for the cost value.</li> <li><code>ignore_errors</code> (bool, default: False): If True, errors encountered during the evaluation of configurations     will be ignored, and the optimization will continue. Note: This error configs still count towards     max_evaluations_total.</li> </ul>"},{"location":"neps_run/#search-strategy-customization","title":"Search Strategy Customization","text":"<ul> <li><code>searcher</code> (Literal[\"bayesian_optimization\", \"hyperband\",..] | BaseOptimizer, default: \"default\"): Specifies     manually which of the optimization strategy to use. Provide a string identifying one of the built-in     search strategies or an instance of a custom <code>BaseOptimizer</code>.</li> <li><code>searcher_path</code> (Path | str, default: None): A path to a custom searcher implementation.</li> <li><code>**searcher_kwargs</code>: Additional keyword arguments to be passed to the searcher.</li> </ul> <p>For more information about the available searchers and how to customize your own, refer here.</p>"},{"location":"neps_run/#others","title":"Others","text":"<ul> <li><code>pre_load_hooks</code> (Iterable, default: None): A list of hook functions to be called before loading results.</li> </ul>"},{"location":"neps_run/#parallelization","title":"Parallelization","text":"<p><code>neps.run</code> can be called multiple times with multiple processes or machines, to parallelize the optimization process. Ensure that <code>root_directory</code> points to a shared location across all instances to synchronize the optimization efforts. For more information look here</p>"},{"location":"neps_run/#customization","title":"Customization","text":"<p>The <code>neps.run</code> function allows for extensive customization through its arguments, enabling to adapt the optimization process to the complexities of your specific problems.</p> <p>For a deeper understanding of how to use <code>neps.run</code> in a practical scenario, take a look at our examples and templates.</p>"},{"location":"optimizers/","title":"Optimizers","text":""},{"location":"optimizers/#optimizer-configuration-options","title":"Optimizer Configuration Options","text":"<p>Before running the optimizer for your AutoML tasks, you have several configuration options to tailor the optimization process to your specific needs. These options allow you to customize the optimizer's behavior according to your preferences and requirements.</p>"},{"location":"optimizers/#1-automatic-optimizer-selection","title":"1. Automatic Optimizer Selection","text":"<p>If you prefer not to specify a particular optimizer for your AutoML task, you can simply pass <code>\"default\"</code> or <code>None</code> for the neps searcher. NePS will automatically choose the best optimizer based on the characteristics of your search space. This provides a hassle-free way to get started quickly.</p> <p>The optimizer selection is based on the following characteristics of your <code>pipeline_space</code>:</p> <ul> <li>If it has fidelity: <code>hyperband</code></li> <li>If it has both fidelity and a prior: <code>priorband</code></li> <li>If it has a prior: <code>pibo</code></li> <li>If it has neither: <code>bayesian_optimization</code></li> </ul> <p>For example, running the following format, without specifying a searcher will choose an optimizer depending on the <code>pipeline_space</code> passed. <pre><code>neps.run(\n    run_pipeline=run_function,\n    pipeline_space=pipeline_space,\n    root_directory=\"results/\",\n    max_evaluations_total=25,\n    # no searcher specified\n)\n</code></pre></p>"},{"location":"optimizers/#2-choosing-one-of-neps-optimizers","title":"2. Choosing one of NePS Optimizers","text":"<p>We have also prepared some optimizers with specific hyperparameters that we believe can generalize well to most AutoML tasks and use cases. For more details on the available default optimizers and the algorithms that can be called, please refer to the next section on SearcherConfigs.</p> <pre><code>neps.run(\n    run_pipeline=run_function,\n    pipeline_space=pipeline_space,\n    root_directory=\"results/\",\n    max_evaluations_total=25,\n    # searcher specified, along with an argument\n    searcher=\"bayesian_optimization\",\n    initial_design_size=5,\n)\n</code></pre> <p>For more optimizers, please refer here .</p>"},{"location":"optimizers/#3-custom-optimizer-configuration-via-yaml","title":"3. Custom Optimizer Configuration via YAML","text":"<p>For users who want more control over the optimizer's hyperparameters, you can create your own YAML configuration file. In this file, you can specify the hyperparameters for your preferred optimizer. To use this custom configuration, provide the path to your YAML file using the <code>searcher_path</code> parameter when running the optimizer. The library will then load your custom settings and use them for optimization.</p> <p>Here's the format of a custom YAML (<code>custom_bo.yaml</code>) configuration using <code>Bayesian Optimization</code> as an example:</p> <pre><code>searcher_init:\n  algorithm: bayesian_optimization\nsearcher_kwargs:  # Specific arguments depending on the searcher\n  initial_design_size: 7\n  surrogate_model: gp\n  acquisition: EI\n  log_prior_weighted: false\n  acquisition_sampler: random\n  random_interleave_prob: 0.1\n  disable_priors: false\n  prior_confidence: high\n  sample_default_first: false\n</code></pre> <pre><code>neps.run(\n    run_pipeline=run_function,\n    pipeline_space=pipeline_space,\n    root_directory=\"results/\",\n    max_evaluations_total=25,\n    # searcher specified, along with an argument\n    searcher_path = \"custom/path/to/directory\"\n    # `custom_bo.yaml` should be in `searcher_path`\n    searcher=\"custom_bo\",\n)\n</code></pre>"},{"location":"optimizers/#4-hyperparameter-overrides","title":"4. Hyperparameter Overrides","text":"<p>If you want to make on-the-fly adjustments to the optimizer's hyperparameters without modifying the YAML configuration file, you can do so by passing keyword arguments (kwargs) to the neps.run function itself. This enables you to fine-tune specific hyperparameters without the need for YAML file updates. Any hyperparameter values provided as kwargs will take precedence over those specified in the YAML configuration.</p> <pre><code>neps.run(\n    run_pipeline=run_function,\n    pipeline_space=pipeline_space,\n    root_directory=\"results/\",\n    max_evaluations_total=25,\n    # searcher specified, along with an argument\n    searcher_path = \"custom/path/to/directory\"\n    # `custom_bo.yaml` should be in `searcher_path`\n    searcher=\"custom_bo\",\n    initial_design_size=5,        # overrides value in custom_bo.yaml\n    random_interleave_prob: 0.25  # overrides value in custom_bo.yaml\n)\n</code></pre>"},{"location":"optimizers/#note-for-contributors","title":"Note for Contributors","text":"<p>When designing a new optimizer, it's essential to create a YAML configuration file in the <code>default_searcher</code> folder under <code>neps.src.optimizers</code>. This YAML file should contain the default configuration settings that you believe should be used when the user chooses the  searcher.</p> <p>Even when many hyperparameters might be set to their default values as specified in the code, it is still considered good practice to include them in the YAML file. This is because the <code>SearcherConfigs</code> method relies on the arguments from the YAML file to display the optimizer's configuration to the user.</p>"},{"location":"optimizers/#searcher-configurations","title":"Searcher Configurations","text":"<p>The <code>SearcherConfigs</code> class provides a set of useful functions to manage and retrieve default configuration details for NePS optimizers. These functions can help you understand and interact with the available searchers and their associated algorithms and configurations.</p>"},{"location":"optimizers/#importing-searcherconfigs","title":"Importing <code>SearcherConfigs</code>","text":"<p>Before you can use the <code>SearcherConfigs</code> class to manage and retrieve default configuration details for NePS optimizers, make sure to import it into your Python script. You can do this with the following import statement:</p> <pre><code>from neps.optimizers.info import SearcherConfigs\n</code></pre> <p>Once you have imported the class, you can proceed to use its functions to explore the available searchers, algorithms, and configuration details.</p>"},{"location":"optimizers/#list-available-searchers","title":"List Available Searchers","text":"<p>To list all the available searchers that can be used in NePS runs, you can use the <code>get_searchers</code> function. It provides you with a list of searcher names:</p> <pre><code>searchers = SearcherConfigs.get_searchers()\nprint(\"Available searchers:\", searchers)\n</code></pre>"},{"location":"optimizers/#list-available-searching-algorithms","title":"List Available Searching Algorithms","text":"<p>The <code>get_available_algorithms</code> function helps you discover the searching algorithms available within the NePS searchers:</p> <pre><code>algorithms = SearcherConfigs.get_available_algorithms()\nprint(\"Available searching algorithms:\", algorithms)\n</code></pre>"},{"location":"optimizers/#find-searchers-using-a-specific-algorithm","title":"Find Searchers Using a Specific Algorithm","text":"<p>If you want to identify which NePS searchers are using a specific searching algorithm (e.g., Bayesian Optimization, Hyperband, PriorBand...), you can use the <code>get_searcher_from_algorithm</code> function. It returns a list of searchers utilizing the specified algorithm:</p> <pre><code>algorithm = \"bayesian_optimization\"  # Replace with the desired algorithm\nsearchers = SearcherConfigs.get_searcher_from_algorithm(algorithm)\nprint(f\"Searchers using {algorithm}:\", searchers)\n</code></pre>"},{"location":"optimizers/#retrieve-searcher-configuration-details","title":"Retrieve Searcher Configuration Details","text":"<p>To access the configuration details of a specific searcher, you can use the <code>get_searcher_kwargs</code> function. Provide the name of the searcher you are interested in, and it will return the searcher's configuration:</p> <pre><code>searcher_name = \"pibo\"  # Replace with the desired NePS searcher name\nsearcher_kwargs = SearcherConfigs.get_searcher_kwargs(searcher_name)\nprint(f\"Configuration of {searcher_name}:\", searcher_kwargs)\n</code></pre> <p>These functions empower you to explore and manage the available NePS searchers and their configurations effectively.</p>"},{"location":"parallelization/","title":"Parallelization and Resuming Runs","text":"<p>NePS utilizes files as a means of communication for implementing parallelization and resuming runs. As a result, when <code>neps.run</code> is called multiple times with the same <code>root_directory</code> in the file system, NePS will automatically load the optimizer state, allowing seamless parallelization of the run across different processes or machines. This concept also applies to resuming runs even after termination.</p> <p>Example:</p> <p>Note</p> <p>The following example assumes all necessary imports are included, in addition to already having defined the pipeline_space and the run_pipeline functions. One can apply the same idea on this example.</p> <pre><code>logging.basicConfig(level=logging.INFO)\n\n# Initial run\nneps.run(\n    run_pipeline=run_pipeline,\n    pipeline_space=pipeline_space,\n    root_directory=\"results/my_example\",\n    max_evaluations_total=5,\n)\n</code></pre> <p>After the initial run, NePS will log the following message:</p> <pre><code>INFO:neps:Maximum total evaluations is reached, shutting down\n</code></pre> <p>If you wish to extend the search with more evaluations, simply update the <code>max_evaluations_total</code> parameter:</p> <pre><code>logging.basicConfig(level=logging.INFO)\n\n\n# Resuming run with increased evaluations\nneps.run(\n    run_pipeline=run_pipeline,\n    pipeline_space=pipeline_space,\n    root_directory=\"results/my_example\",\n    max_evaluations_total=10,\n)\n</code></pre> <p>Now, NePS will continue the search, loading the latest information for the searcher. For parallelization, as mentioned above, you can also run this code multiple times on different processes or machines. The file system communication will link them, as long as the <code>root_directory</code> has the same location.</p>"},{"location":"pipeline_space/","title":"Initializing the Pipeline Space","text":"<p>In NePS, a pivotal step is the definition of the search space, termed <code>pipeline_space</code>. This space can be structured through various approaches, including a Python dictionary, a YAML file, or ConfigSpace. Each of these methods allows you to specify a set of parameter types, ranging from Float and Categorical to specialized architecture parameters. Whether you choose a dictionary, YAML file, or ConfigSpace, your selected method serves as a container or framework within which these parameters are defined and organized. This section not only guides you through the process of setting up your <code>pipeline_space</code> using these methods but also provides detailed instructions and examples on how to effectively incorporate various parameter types, ensuring that NePS can utilize them in the optimization process.</p>"},{"location":"pipeline_space/#methods-for-defining-the-neps-pipeline-space","title":"Methods for Defining the NePS Pipeline Space","text":""},{"location":"pipeline_space/#option-1-using-a-python-dictionary","title":"Option 1: Using a Python Dictionary","text":"<p>To define the <code>pipeline_space</code> using a Python dictionary, follow these steps:</p> <p>Create a Python dictionary that specifies the parameters and their respective ranges. For example:</p> <pre><code>pipeline_space = {\n    \"learning_rate\": neps.FloatParameter(lower=0.00001, upper=0.1, log=True),\n    \"num_epochs\": neps.IntegerParameter(lower=3, upper=30, is_fidelity=True),\n    \"optimizer\": neps.CategoricalParameter(choices=[\"adam\", \"sgd\", \"rmsprop\"]),\n    \"dropout_rate\": neps.FloatParameter(value=0.5),\n}\n</code></pre>"},{"location":"pipeline_space/#option-2-using-a-yaml-file","title":"Option 2: Using a YAML File","text":"<p>Create a YAML file (e.g., pipeline_space.yaml) with the parameter definitions following this structure.</p> <pre><code>pipeline_space: # important to start with\n  learning_rate:\n    lower: 2e-3\n    upper: 0.1\n    log: true\n\n  num_epochs:\n    type: int # or \"integer\", optional if u want to manually set this\n    lower: 3\n    upper: 30\n    is_fidelity: True\n\n  optimizer:\n    choices: [\"adam\", \"sgd\", \"rmsprop\"]\n\n  dropout_rate:\n    value: 0.5\n...\n</code></pre> <p>Ensure your YAML file starts with <code>pipeline_space:</code>. This is the root key under which all parameter configurations are defined.</p> <p>Note</p> <p>The various types of parameters displayed in the Dictionary of Option 1 are here automatically determined by the data. If desired, you have the option to define them manually by providing the argument <code>type</code>. For more details, refer to the section on Supported Hyperparameter Types.</p>"},{"location":"pipeline_space/#option-3-using-configspace","title":"Option 3: Using ConfigSpace","text":"<p>For users familiar with the ConfigSpace library, can also define the <code>pipeline_space</code> through ConfigurationSpace().</p> <pre><code>from configspace import ConfigurationSpace, UniformFloatHyperparameter\n\nconfigspace = ConfigurationSpace()\nconfigspace.add_hyperparameter(\n    UniformFloatHyperparameter(\"learning_rate\", 0.00001, 0.1, log=True)\n)\n</code></pre> <p>For additional information on ConfigSpace and its features, please visit the following link.</p>"},{"location":"pipeline_space/#supported-hyperparameter-types","title":"Supported Hyperparameter Types","text":""},{"location":"pipeline_space/#floatinteger-parameter","title":"Float/Integer Parameter","text":"<ul> <li>Expected Arguments:<ul> <li><code>lower</code>: The minimum value of the parameter.</li> <li><code>upper</code>: The maximum value of the parameter.<ul> <li>Accepted values: int or float depending on the specific parameter type one wishes to use.</li> </ul> </li> </ul> </li> <li>Optional Arguments:<ul> <li><code>log</code>: Boolean that indicates if the parameter uses a logarithmic scale (default: False)<ul> <li>Details on how YAML interpret Boolean Values</li> </ul> </li> <li><code>is_fidelity</code>: Boolean that marks the parameter as a fidelity parameter (default: False).</li> <li><code>default</code>: Sets a prior central value for the parameter (default: None). <p>Note: Currently, if you define a prior for one parameter, you must do so for all your variables.</p> </li> <li><code>default_confidence</code>: Specifies the confidence level of the default value,   indicating how strongly the prior   should be considered (default: 'low').<ul> <li>Accepted values: 'low', 'medium', or 'high'.</li> </ul> </li> <li> <p><code>type</code>: Specifies the data type of the parameter.</p> <ul> <li>Accepted values: 'int', 'integer', or 'float'. <p>Note: If type is not specified e notation gets converted to float</p> </li> </ul> <p>YAML Method Specific:</p> <p>The type argument, used to specify the data type of parameters as 'int', 'integer', or 'float', is unique to defining the pipeline_space with a YAML file. This explicit specification of the parameter type is not required when using a Python dictionary or ConfigSpace, as these methods inherently determine the data types based on the syntax and structure of the code.</p> </li> </ul> </li> </ul>"},{"location":"pipeline_space/#categorical-parameter","title":"Categorical Parameter","text":"<ul> <li>Expected Arguments:<ul> <li><code>choices</code>: A list of discrete options (int | float | str) that the parameter can take.</li> </ul> </li> <li>Optional Arguments:<ul> <li><code>is_fidelity</code>: Marks the parameter as a fidelity parameter (default: False).<ul> <li>Details on how YAML interpret Boolean Values</li> </ul> </li> <li><code>default</code>: Sets a prior central value for the parameter (default: None). <p>Note: Currently, if you define a prior for one parameter, you must do so for all your variables.</p> </li> <li><code>default_confidence</code>: Specifies the confidence level of the default value,   indicating how strongly the prior   should be considered (default: \"low\").</li> <li><code>type</code>: Specifies the data type of the parameter.<ul> <li>Accepted values: 'cat' or 'categorical'. <p>Note: Yaml Method Specific</p> </li> </ul> </li> </ul> </li> </ul>"},{"location":"pipeline_space/#constant-parameter","title":"Constant Parameter","text":"<ul> <li>Expected Arguments:<ul> <li><code>value</code>: The fixed value (int | float | str) for the parameter.</li> </ul> </li> <li>Optional Arguments:<ul> <li><code>type</code>: Specifies the data type of the parameter.<ul> <li>Accepted values: 'const' or 'constant'. <p>Note: Yaml Method Specific</p> </li> </ul> </li> <li><code>is_fidelity</code>: Marks the parameter as a fidelity parameter (default: False).</li> </ul> </li> </ul>"},{"location":"pipeline_space/#important-note-on-yaml-data-type-interpretation","title":"Important Note on YAML Data Type Interpretation","text":"<p>When working with YAML files, it's essential to understand how the format interprets different data types:</p> <ol> <li> <p>Strings in Quotes:</p> <ul> <li>Any value enclosed in single (<code>'</code>) or double (<code>\"</code>) quotes is treated as a string.</li> <li>Example: <code>\"true\"</code>, <code>'123'</code> are read as strings.</li> </ul> </li> <li> <p>Boolean Interpretation:</p> <ul> <li>Specific unquoted values are interpreted as booleans. This includes:<ul> <li><code>true</code>, <code>True</code>, <code>TRUE</code></li> <li><code>false</code>, <code>False</code>, <code>FALSE</code></li> <li><code>on</code>, <code>On</code>, <code>ON</code></li> <li><code>off</code>, <code>Off</code>, <code>OFF</code></li> <li><code>yes</code>, <code>Yes</code>, <code>YES</code></li> <li><code>no</code>, <code>No</code>, <code>NO</code></li> </ul> </li> </ul> </li> <li> <p>Numbers:</p> <ul> <li>Unquoted numeric values are interpreted as integers or floating-point numbers, depending on their format.</li> <li>By default, when the 'type' is not specified, any number in scientific notation (e.g., 1e3) is interpreted as a    floating-point number. This interpretation is unique to our system.</li> </ul> </li> <li> <p>Empty Strings:</p> <ul> <li>An empty string <code>\"\"</code> or a key with no value is always treated as <code>null</code> in YAML.</li> </ul> </li> <li> <p>Unquoted Non-Boolean, Non-Numeric Strings:</p> <ul> <li>Unquoted values that don't match boolean patterns or numeric formats are treated as strings.</li> <li>Example: <code>example</code> is a string.</li> </ul> </li> </ol> <p>Remember to use appropriate quotes and formats to ensure values are interpreted as intended.</p>"},{"location":"pipeline_space/#supported-architecture-parameter-types","title":"Supported Architecture parameter Types","text":"<p>Note</p> <p>The configuration of <code>pipeline_space</code> from a YAML file does not currently support architecture parameter types.</p> <p>Note</p> <p>A comprehensive documentation for the Architecture parameter will be available soon. If you are interested in exploring architecture parameters, you can find detailed examples and usage in the following resources:</p> <ul> <li>Basic Usage Examples - Basic usage     examples that can help you understand the fundamentals of Architecture parameters.</li> <li>Experimental Examples - For more advanced     and experimental use cases, including Hierarchical parameters, check out this collection of examples.</li> </ul>"},{"location":"run_pipeline/","title":"The run_pipeline Function","text":""},{"location":"run_pipeline/#introduction","title":"Introduction","text":"<p>The <code>run_pipeline</code> function is crucial for NePS. It encapsulates the objective function to be minimized, which could range from a regular equation to a full training and evaluation pipeline for a neural network.</p> <p>This function receives the configuration to be utilized from the parameters defined in the search space. Consequently, it executes the same set of instructions or equations based on the provided configuration to minimize the objective function.</p> <p>We will show some basic usages and some functionalites this function would require for successful implementation.</p>"},{"location":"run_pipeline/#types-of-returns","title":"Types of Returns","text":""},{"location":"run_pipeline/#1-single-value","title":"1. Single Value","text":"<p>Assuming the <code>pipeline_space</code> was already created (have a look at pipeline space for more details). A <code>run_pipeline</code> function with an objective of minimizing the loss will resemble the following:</p> <pre><code>def run_pipeline(\n    **config,   # The hyperparameters to be used in the pipeline\n):\n    element_1 = config[\"element_1\"]\n    element_2 = config[\"element_2\"]\n    element_3 = config[\"element_3\"]\n\n    loss = element_1 - element_2 + element_3\n\n    return loss\n</code></pre>"},{"location":"run_pipeline/#2-dictionary","title":"2. Dictionary","text":"<p>In this section, we will outline the special variables that are expected to be returned when the <code>run_pipeline</code> function returns a dictionary.</p>"},{"location":"run_pipeline/#loss","title":"Loss","text":"<p>One crucial return variable is the <code>loss</code>. This metric serves as a fundamental indicator for the optimizer. One option is to return a dictionary with the <code>loss</code> as a key, along with other user-chosen metrics.</p> <p>Note</p> <p>Loss can be any value that is to be minimized by the objective function.</p> <pre><code>def run_pipeline(\n    **config,   # The hyperparameters to be used in the pipeline\n):\n\n    element_1 = config[\"element_1\"]\n    element_2 = config[\"element_2\"]\n    element_3 = config[\"element_3\"]\n\n    loss = element_1 - element_2 + element_3\n    reverse_loss = -loss\n\n    return {\n        \"loss\": loss,\n        \"info_dict\": {\n            \"reverse_loss\": reverse_loss\n            ...\n        }\n    }\n</code></pre>"},{"location":"run_pipeline/#cost","title":"Cost","text":"<p>Along with the return of the <code>loss</code>, the <code>run_pipeline</code> function would optionally need to return a <code>cost</code> in certain cases. Specifically when the <code>max_cost_total</code> parameter is being utilized in the <code>neps.run</code> function.</p> <p>Note</p> <p><code>max_cost_total</code> sums the cost from all returned configuration results and checks whether the maximum allowed cost has been reached (if so, the search will come to an end).</p> <pre><code>import neps\nimport logging\n\n\ndef run_pipeline(\n    **config,   # The hyperparameters to be used in the pipeline\n):\n\n    element_1 = config[\"element_1\"]\n    element_2 = config[\"element_2\"]\n    element_3 = config[\"element_3\"]\n\n    loss = element_1 - element_2 + element_3\n    cost = 2\n\n    return {\n        \"loss\": loss,\n        \"cost\": cost,\n    }\n\nif __name__ == \"__main__\":\n    logging.basicConfig(level=logging.INFO)\n    neps.run(\n        run_pipeline=run_pipeline,\n        pipeline_space=pipeline_space, # Assuming the pipeline space is defined\n        root_directory=\"results/bo\",\n        max_cost_total=10,\n        searcher=\"bayesian_optimization\",\n    )\n</code></pre> <p>Each evaluation carries a cost of 2. Hence in this example, the Bayesian optimization search is set to perform 5 evaluations.</p>"},{"location":"run_pipeline/#arguments-for-convenience","title":"Arguments for Convenience","text":"<p>NePS also provides the <code>pipeline_directory</code> and the <code>previous_pipeline_directory</code> as arguments in the <code>run_pipeline</code> function for user convenience.</p> <p>Regard an example to be run with a multi-fidelity searcher, some checkpointing would be advantageos such that one does not have to train the configuration from scratch when the configuration qualifies to higher fidelity brackets.</p> <pre><code>def run_pipeline(\n    pipeline_directory,           # The directory where the config is saved\n    previous_pipeline_directory,  # The directory of the immediate lower fidelity config\n    **config,                     # The hyperparameters to be used in the pipeline\n):\n    # Assume element3 is our fidelity element\n    element_1 = config[\"element_1\"]\n    element_2 = config[\"element_2\"]\n    element_3 = config[\"element_3\"]\n\n    # Load any saved checkpoints\n    checkpoint_name = \"checkpoint.pth\"\n    start_element_3 = 0\n\n    if previous_pipeline_directory is not None:\n        # Read in state of the model after the previous fidelity rung\n        checkpoint = torch.load(previous_pipeline_directory / checkpoint_name)\n        prev_element_3 = checkpoint[\"element_3\"]\n    else:\n        prev_element_3 = 0\n\n    start_element_3 += prev_element_3\n\n    loss = 0\n    for i in range(start_element_3, element_3):\n        loss += element_1 - element_2\n\n    torch.save(\n        {\n            \"element_3\": element_3,\n        },\n        pipeline_directory / checkpoint_name,\n    )\n\n    return loss\n</code></pre> <p>This could allow the proper navigation to the trained models and further train them on higher fidelities without repeating the entire training process.</p>"},{"location":"contributing/","title":"Introduction","text":""},{"location":"contributing/#getting-help","title":"Getting Help","text":"<p>Ask in the neps contributor chat on mattermost or any contributor directly. If you are not in the mattermost chat yet, ask to get access.</p>"},{"location":"contributing/#development-workflow","title":"Development Workflow","text":"<p>We loosely practice trunk-based-development:</p> <ul> <li>We work almost exclusively on the master branch</li> <li>We commit, push, and pull often</li> <li>We automatically run code quality checks before every commit (using pre-commit)</li> <li>We manually run tests (using <code>pytest</code>) before every critical push and automatically afterwards (using github actions)</li> </ul>"},{"location":"contributing/#installation","title":"Installation","text":"<p>For the contributor installation process see Installation.</p>"},{"location":"contributing/#checks-and-tests","title":"Checks and tests","text":"<p>The documentation also includes an overview on the protocols and tools we use for code quality checks and tests.</p>"},{"location":"contributing/dependencies/","title":"Managing Dependencies","text":"<p>To manage dependencies and for package distribution we use poetry (replaces pip).</p>"},{"location":"contributing/dependencies/#add-dependencies","title":"Add dependencies","text":"<p>To install a dependency use</p> <pre><code>poetry add dependency\n</code></pre> <p>and commit the updated <code>pyproject.toml</code> to git.</p> <p>For more advanced dependency management see examples in <code>pyproject.toml</code> or have a look at the poetry documentation.</p>"},{"location":"contributing/dependencies/#install-dependencies-added-by-others","title":"Install dependencies added by others","text":"<p>When other contributors added dependencies to <code>pyproject.toml</code>, you can install them via</p> <pre><code>poetry lock\npoetry install\n</code></pre>"},{"location":"contributing/documentation/","title":"Documentation","text":"<p>We use MkDocs, more specifically Material for MkDocs for documentation. To support documentation for multiple versions, we use the plugin mike. Source files for the documentation are at docs and configuration at  mkdocs.yml.</p> <p>To build and view the documentation run</p> <pre><code>mike deploy 0.5.1 latest\nmike serve\n</code></pre> <p>and open the URL shown by the <code>mike serve</code> command.</p> <p>To publish the documentation run</p> <pre><code>mike deploy 0.5.1 latest -p\n</code></pre>"},{"location":"contributing/installation/","title":"Installation for Contributors","text":"<p>There are three required steps and one optional:</p> <ol> <li>Optional: Install miniconda and create an environment</li> <li>Install poetry</li> <li>Install the neps package using poetry</li> <li>Activate pre-commit for the repository</li> </ol> <p>For instructions see below.</p>"},{"location":"contributing/installation/#1-optional-install-miniconda-and-create-an-environment","title":"1. Optional: Install miniconda and create an environment","text":"<p>To manage python versions install e.g., miniconda with</p> <pre><code>wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh -O install_miniconda.sh\nbash install_miniconda.sh -b -p $HOME/.conda  # Change to place of preference\nrm install_miniconda.sh\n</code></pre> <p>Consider running <code>~/.conda/bin/conda init</code> or <code>~/.conda/bin/conda init zsh</code> .</p> <p>Then finally create the environment and activate it</p> <pre><code>conda create -n neps python=3.10\nconda activate neps\n</code></pre>"},{"location":"contributing/installation/#2-install-poetry","title":"2. Install poetry","text":"<p>First, install poetry, e.g., via</p> <pre><code>curl -sSL https://install.python-poetry.org | python3 -\n</code></pre> <p>Then consider appending</p> <pre><code>export PATH=\"$HOME/.local/bin:$PATH\"\n</code></pre> <p>to your <code>.zshrc</code> / <code>.bashrc</code> or alternatively simply running the export manually.</p>"},{"location":"contributing/installation/#3-install-the-neps-package-using-poetry","title":"3. Install the neps Package Using poetry","text":"<p>Clone the repository, e.g.,</p> <pre><code>git clone https://github.com/automl/neps.git\ncd neps\n</code></pre> <p>Then, inside the main directory of neps run</p> <pre><code>poetry install\n</code></pre>"},{"location":"contributing/installation/#4-activate-pre-commit-for-the-repository","title":"4. Activate pre-commit for the repository","text":"<p>With the python environment used to install the neps package run in the main directory of neps</p> <pre><code>pre-commit install\n</code></pre>"},{"location":"contributing/releasing/","title":"Releasing a New Version","text":"<p>There are four steps to releasing a new version of neps:</p> <ol> <li>Understand Semantic Versioning</li> <li>Update the Package Version</li> <li>Commit and Push With a Version Tag</li> <li>Update Documentation</li> <li>Publish on PyPI</li> </ol>"},{"location":"contributing/releasing/#0-understand-semantic-versioning","title":"0. Understand Semantic Versioning","text":"<p>We follow the semantic versioning scheme.</p>"},{"location":"contributing/releasing/#1-update-the-package-version-and-citationcff","title":"1. Update the Package Version and CITATION.cff","text":"<pre><code>poetry version v0.9.0\n</code></pre> <p>and manually change the version specified in <code>CITATION.cff</code>.</p>"},{"location":"contributing/releasing/#2-commit-with-a-version-tag","title":"2. Commit with a Version Tag","text":"<p>First commit and test</p> <pre><code>git add pyproject.toml\ngit commit -m \"Bump version from v0.8.4 to v0.9.0\"\npytest\n</code></pre> <p>Then tag and push</p> <pre><code>git tag v0.9.0\ngit push --tags\ngit push\n</code></pre>"},{"location":"contributing/releasing/#3-update-documentation","title":"3. Update Documentation","text":"<p>First check if the documentation has any issues via</p> <pre><code>mike deploy 0.9.0 latest -u\nmike serve\n</code></pre> <p>and then looking at it.</p> <p>Afterwards, publish it via</p> <pre><code>mike deploy 0.9.0 latest -up\n</code></pre>"},{"location":"contributing/releasing/#4-publish-on-pypi","title":"4. Publish on PyPI","text":"<p>To publish to PyPI:</p> <ol> <li>Get publishing rights, e.g., asking Danny or Maciej or Neeratyoy.</li> <li>Be careful, once on PyPI we can not change things.</li> <li>Run</li> </ol> <pre><code>poetry publish --build\n</code></pre> <p>This will ask for your PyPI credentials.</p>"},{"location":"contributing/roadmap/","title":"Roadmap","text":""},{"location":"contributing/roadmap/#before-0120","title":"Before 0.12.0","text":""},{"location":"contributing/roadmap/#features","title":"Features","text":"<ul> <li>Allow yaml based input of search space and the target function source to <code>neps.run</code></li> <li>Generate plot after each evaluation</li> <li>Support conditionals in ConfigSpace search space</li> <li>Support logging of optimizer state details</li> </ul>"},{"location":"contributing/roadmap/#fixes","title":"Fixes","text":"<ul> <li>Open never closes (talk to Nils)</li> <li>Deadlock in ASHA-like optimizers (talk to Neeratyoy)</li> <li>Extra metahyper sample in issue 42</li> <li>Tighter type check in search space</li> <li>Unify MFObservedData class for both Hyperband-like fidelities and one-step fidelities</li> </ul>"},{"location":"contributing/roadmap/#documentation","title":"Documentation","text":"<ul> <li>Improved documentation on all basic usage</li> <li>Improved README on github that links to the documentations</li> <li>Adequate examples targeting different user groups</li> </ul>"},{"location":"contributing/roadmap/#refactoring","title":"Refactoring","text":"<ul> <li>Merge GP and hierarchical GP</li> <li>Merge gpytorch branch</li> <li>Rethink summary/status API</li> <li>Improve placement of _post_evaluation_hook_function</li> <li>maintained vs unmaintained optimizers</li> <li>Read and sample at the same time metahyper</li> <li>Metahyper into neps</li> <li>Renamings</li> <li>run_pipeline = evaluate_pipeline | evaluate_pipeline_error | compute_pipeline_error | train_and_evaluate</li> <li>loss = validation_error | error | pipeline_error</li> <li>XParameter = XSpace</li> <li>Rename default-x to prior-x</li> <li>Use max_cost_total everywhere instead of budget</li> </ul>"},{"location":"contributing/roadmap/#tests-and-tooling","title":"Tests and tooling","text":"<ul> <li>Add priorband to experimental</li> <li>Add simple regression tests to run on each push</li> </ul>"},{"location":"contributing/roadmap/#before-100-version","title":"Before 1.0.0 version","text":""},{"location":"contributing/roadmap/#features_1","title":"Features","text":"<ul> <li>Seamless ddp via cli launcher</li> <li>Finegrained control over HP user prior</li> <li>Top vs all vs bottom distribution plots</li> <li>Tensorboard visualizations (incumbent plot, ..)</li> <li>Loss distribution plot</li> <li>Print search space upon run</li> <li>Add comprehensive regression tests to run manually on the cluster on each version release</li> <li>Utility to generate code for best architecture</li> <li>Core Feature set in terms of research</li> <li>Modular plug-and-play of BoTorch acquisition functions</li> <li>Exploring gradient-based HPO in the NePS framework</li> </ul>"},{"location":"contributing/roadmap/#fixes_1","title":"Fixes","text":"<ul> <li>Printing architecture search spaces / search spaces in general</li> <li>Metahyper Refine jobtimelimit feature</li> <li>Optimize dependencies</li> </ul>"},{"location":"contributing/roadmap/#refactoring_1","title":"Refactoring","text":"<ul> <li>Clean up search spaces classes, unused methods</li> <li>Break up search space and config aspect</li> <li>Remove hnas branch</li> <li>Refactor of constraint grammar</li> </ul>"},{"location":"contributing/roadmap/#documentation_1","title":"Documentation","text":"<ul> <li>Keep a changelog</li> </ul>"},{"location":"contributing/roadmap/#later-version","title":"Later version","text":""},{"location":"contributing/roadmap/#features_2","title":"Features","text":"<ul> <li>neps_examples callable for options of examples</li> <li>Optional argparse adder like pytorch lightning</li> <li>Utility neps.clean to manage existing run results</li> <li>Collect data optionally via phone-home to webserver</li> <li>Add Info dict to status</li> <li>Seed (setting context manager?)</li> <li>BO improvements via Hebo tricks + Mll replacement</li> <li>Checkout Rich logging</li> </ul>"},{"location":"contributing/roadmap/#miscellaneous","title":"Miscellaneous","text":"<ul> <li>User Mattermost Channel</li> <li>Twitter handle and domain, e.g., neural-pipeline.search</li> <li>Doing research with NePS / Documentation on that or full setup</li> </ul>"},{"location":"contributing/tests/","title":"Checks and Tests","text":"<p>We have setup checks and tests at several points in the development flow:</p> <ul> <li>At every commit we automatically run a suite of pre-commit hooks that perform static code analysis, autoformating, and sanity checks. This is setup during our installation process.</li> <li>At every commit / push locally running a minimal suite of integration tests is encouraged. The tests correspond directly to examples in neps_examples and only check for crash-causing errors.</li> <li>At every push all integration tests and regression tests are run automatically using github actions.</li> </ul>"},{"location":"contributing/tests/#examples-and-integration-tests","title":"Examples and Integration Tests","text":"<p>We use examples in neps_examples as integration tests, which we run from the main directory via</p> <pre><code>pytest\n</code></pre> <p>before every critical push.</p>"},{"location":"contributing/tests/#creating-an-integration-test","title":"Creating an Integration Test","text":"<p>If you want an implementation to be included in the above testing procedure:</p> <ol> <li>Create an example in neps_examples.</li> <li>Add the example to test_examples.py.</li> </ol>"},{"location":"contributing/tests/#running-all-integration-tests-locally","title":"Running all integration tests locally","text":"<p>To speedup testing for developers, we only run a core set of tests per default. To run all tests use</p> <pre><code>pytest -m all_examples\n</code></pre> <p>On github, we always run all examples.</p>"},{"location":"contributing/tests/#what-to-do-if-tests-fail","title":"What to do if tests fail","text":"<p>If tests fail for you on the master:</p> <ol> <li>Try running the tests with a fresh environment install.</li> <li>If issues persist, notify others in the neps developers chat on mattermost.</li> </ol>"},{"location":"contributing/tests/#regression-tests","title":"Regression Tests","text":"<p>Regression tests are run on each push to the repository to assure the performance of the optimizers don't degrade.</p> <p>Currently, regression runs are recorded on JAHS-Bench-201 data for 2 tasks: <code>cifar10</code> and <code>fashion_mnist</code> and only for optimizers: <code>random_search</code>, <code>bayesian_optimization</code>, <code>mf_bayesian_optimization</code>, <code>regularized_evolution</code>. This information is stored in the <code>tests/regression_runner.py</code> as two lists: <code>TASKS</code>, <code>OPTIMIZERS</code>. The recorded results are stored as a json dictionary in the <code>tests/losses.json</code> file.</p>"},{"location":"contributing/tests/#adding-new-optimizer-algorithms","title":"Adding new optimizer algorithms","text":"<p>Once a new algorithm is added to NEPS library, we need to first record the performance of the algorithm for 100 optimization runs.</p> <ul> <li> <p>If the algorithm expects standard loss function (pipeline) and accepts fidelity hyperparameters in pipeline space, then recording results only requires adding the optimizer name into <code>OPTIMIZERS</code> list in <code>tests/regression_runner.py</code> and running <code>tests/regression_runner.py</code></p> </li> <li> <p>In case your algorithm requires custom pipeline and/or pipeline space you can modify the <code>runner.run_pipeline</code> and <code>runner.pipeline_space</code> attributes of the <code>RegressionRunner</code> after initialization (around line <code>#322</code> in <code>tests/regression_runner.py</code>)</p> </li> </ul> <p>You can verify the optimizer is recorded by rerunning the <code>regression_runner.py</code>. Now regression test will be run on your new optimizer as well on every push.</p>"},{"location":"contributing/tests/#regression-test-metrics","title":"Regression test metrics","text":"<p>For each regression test the algorithm is run 10 times to sample its performance, then they are statistically compared to the 100 recorded runs. We use these 3 boolean metrics to define the performance of the algorithm on any task:</p> <ol> <li>Kolmogorov-Smirnov test for goodness of fit - <code>pvalue</code> &gt;= 10%</li> <li>Absolute median distance - bounded within 92.5% confidence range of the expected median distance</li> <li>Median improvement - Median improvement over the recorded median</li> </ol> <p>Test metrics are run for each <code>(optimizer, task)</code> combination separately and then collected. The collected metrics are then further combined into 2 metrics</p> <ol> <li>Task pass - either both <code>Kolmogorov-Smirnov test</code> and <code>Absolute median distance</code> test passes or just <code>Median improvement</code></li> <li>Test aggregate - Sum_over_tasks(<code>Kolmogorov-Smirnov test</code> + <code>Absolute median distance</code> + 2 * <code>Median improvement</code>)</li> </ol> <p>Finally, a test for an optimizer only passes when at least for one of the tasks <code>Task pass</code> is true, and <code>Test aggregate</code> is higher than 1 + <code>number of tasks</code></p>"},{"location":"contributing/tests/#on-regression-test-failures","title":"On regression test failures","text":"<p>Regression tests are stochastic by nature, so they might fail occasionally even the algorithm performance didn't degrade. In the case of regression test failure, try running it again first, if the problem still persists, then you can contact Danny Stoll or Samir. You can also run tests locally by running:</p> <pre><code>poetry run pytest -m regression_all\n</code></pre>"},{"location":"contributing/tests/#disabling-and-skipping-checks-etc","title":"Disabling and Skipping Checks etc.","text":""},{"location":"contributing/tests/#pre-commit-how-to-not-run-hooks","title":"Pre-commit: How to not run hooks?","text":"<p>To commit without running <code>pre-commit</code> use <code>git commit --no-verify -m &lt;COMMIT MESSAGE&gt;</code>.</p>"},{"location":"contributing/tests/#pylint-how-to-ignore-warnings","title":"Pylint: How to ignore warnings?","text":"<p>There are two options:</p> <ul> <li>Disable the warning locally:</li> </ul> <pre><code>code = \"foo\"  # pylint: disable=ERROR_CODE\n</code></pre> <p>Make sure to use the named version of the error (e.g., <code>unspecified-encoding</code>, not <code>W1514</code>).</p> <ul> <li>Remove warning in <code>pyproject.toml</code> that we do not consider useful (do not catch bugs, do not increase code quality).</li> </ul>"},{"location":"contributing/tests/#mypy-how-to-ignore-warnings","title":"Mypy: How to ignore warnings?","text":"<p>There are two options:</p> <ul> <li>Disable the warning locally:</li> </ul> <pre><code>code = \"foo\"  # type: ignore[ERROR_CODE]\n</code></pre> <ul> <li>If you know what you are doing, you can add the whole module to the <code>[[tool.mypy.overrides]]</code> section.   This is useful e.g., when adding new files that are in early stage development.</li> </ul>"},{"location":"contributing/tests/#black-how-to-not-format-code-parts","title":"Black: How to not format code parts?","text":"<pre><code>x = 2  # fmt: off\n</code></pre> <p>or for blocks</p> <pre><code># fmt: off\nx = 2\ny = x + 1\n# fmt: on\n</code></pre>"}]}